{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Final Project - Predicting Movie Genres!\n",
    "\n",
    "![Movie genre header](genre_header.jpg)\n",
    "\n",
    "Welcome to the final project of CS109b. \n",
    "\n",
    "The overall theme of the final project is movie data with a focus on movie genre prediction, because it is an area where we are all more or less application domain experts. First, you will explore your data and the challenges of the problem by exploratory data analysis. Use visualizations to find features that correlate with movie genres. These can be extracted from the movie posters, or meta data, or other data you gather, for example plot summaries or even movie transcripts. You will then compare traditional statistical or machine learning methods like generalized additive models, random forest, Bayesian prediction methods, boosting, and SVM, to deep learning models for movie genre prediction. \n",
    "\n",
    "For this project you will work in teams of 3-4 people and there are weekly milestones to guide you along the way. Even though the milestones are graded, they are mainly in place to make sure you stay in contact with your TF and make progress with the project. Throughout the project you also have room for creativity and to pursue your own ideas. While you need to hand in the milestones at the appropriate due date, there is nothing preventing you from working on a later milestone ahead of time. We suggest that you read through the whole project and all milestones in the beginning to be able to plan ahead. The project is pretty open-ended, so you can be creative and let your data science knowledge shine! \n",
    "\n",
    "For each milestone you will submit a notebook, in raw (`.ipynb`) and PDF formats, containing the deliverables of that week and the extra work you did so far. The notebooks need to contain your code, comments, explanations, thoughts, and visualizations. The final deliverables are a two-minute screencast, a report in paper style for a general data science audience, and all your data and code that you developed throughout the project. \n",
    "\n",
    "Below is a description of the data and the milestones with their due dates. All work is due by 11:59PM on the due date unless otherwise specified. We expect you to have the mandatory parts finished by the milestone due dates, and there will be no extensions. However, we strongly encourage you to plan ahead. For example, you need to think about the classification task early on to plan how you want to assemble your training data, and it is beneficial to start the deep learning work as early as possible. There is nothing hindering you to already train a model in the EDA phase to get a better feel for what challenges might lie ahead with the data. You should also see the milestone requirements as a basis for your own creativity, and we expect that most of you will go beyond the mandatory deliverables. For example, if you have a great idea about an interesting question that has to do with movie genre, but cannot be answered with the data from TMDb or IMDb, feel free to gather more data from somewhere else. \n",
    "\n",
    "We provide a data interface in Python, because it is convenient for IMDb, and we will use Python for the deep learning part. Specifically we will use Keras, a deep learning library that provides a high level interface to Google's Tensorflow framework for deep learning. However, if you feel that you prefer to do some of the work, e.g., visualizations or data cleanup, in R then feel free to use it. You can also use Spark to preprocess your data, especially if you collect large amounts of it from other sources. \n",
    "\n",
    "*Important:* Your grade for a milestone will depend on the required deliverables you submit at the due date for that milestone. But every milestone, especially the final project submission, can contain additional cool work you did that goes beyond the deliverables spelled out below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Logistics \n",
    "\n",
    "Please adhere to the following guidelines for all submissions:\n",
    "- one submission per team\n",
    "- notebooks should be submitted as PDF and as raw (`.ipynb`) version\n",
    "- all notebooks should be executed so they contain relevant visualizations, and other results\n",
    "- try to make it as easy as possible for the TFs to get all relevant information about your work\n",
    "- do not submit big data sets, please provide a readme file with a link instead\n",
    "- the final report should also be submitted as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Movie Data:\n",
    "\n",
    "The project is based on two different sources of movie data: [IMDb](http://www.imdb.com/) and [TMDb](https://www.themoviedb.org/). TMDb is great, because it provides the movie posters in addition to the metadata. This is crucial for the deep learning part, in which you will try to predict movie genres from posters. IMDb has more metadata available and will supplement the TMDb data you have. \n",
    "\n",
    "TMDb provides an easy to use [API](https://www.themoviedb.org/documentation/api) that allows you to download the data selectively. IMDb does not provide an API, but there is a Python interface available to access the metadata. We will use [IMDbPY](http://imdbpy.sourceforge.net/), which is already installed on the AMI and virtual box images for your convenience.\n",
    "\n",
    "*Important*: Please remember to limit your data rate when obtaining the data. Play nicely and do not just spam servers as fast as you can. This will prevent your IP from getting banned. The easiest way to do this is to use the [sleep](http://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python) function in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 1: Getting to know your data, due Wednesday, April 5, 2017\n",
    "\n",
    "In the beginning you should get acquainted with the data sources and do some EDA. Sign up for the TMDb [API](https://www.themoviedb.org/documentation/api), and try to download the poster of your favorite movie from within your notebook. Compare the genre entries of IMDb and TMDb for this movie and see if they are the same. Think about and write down some questions that you would like to answer in the following weeks. Keep the storytelling aspect of your final report in mind and do some pen and paper sketches about the visualizations you would like to produce. Include photographs of those sketches in your notebook. \n",
    "\n",
    "Most of the time a data scientist spends on a project is spent on cleaning the data. We are lucky that the data we have is already pretty clean. The Python interface to the IMDb ftp files does a lot of the additional work of cleaning as well. However, you will notice that the genre list for each movie from both databases can have different lengths. This needs to be changed in order to train a model to predict the movie genre. It is up to you to think about possible ways to address this problem and to implement one of them. There is no absolute right answer here. It depends on your interests and which questions you have in mind for the project. \n",
    "\n",
    "Optionally, you could also scrape additional data sources, such as Wikipedia, to obtain plot summaries. That data may give you additional useful features for genre classification. \n",
    "\n",
    "To guide your decision process, provide at least one visualization of how often genres are mentioned together in pairs. Your visualization should clearly show if a horror romance is more likely to occur in the data than a drama romance.\n",
    "\n",
    "The notebook to submit for this milestone needs to at least include:\n",
    "\n",
    "- API code to access the genre and movie poster path of your favorite movie\n",
    "- Genre for this movie listed by TMDb and IMDb\n",
    "- A list of the 10 most popular movies of 2016 from TMDb and their genre obtained via the API\n",
    "- Comments on what challenges you see for predicting movie genre based on the data you have, and how to address them \n",
    "- Code to generate the movie genre pairs and a suitable visualization of the result\n",
    "- Additional visualization sketches and EDA with a focus on movie genres\n",
    "- A list of questions you could answer with this and related data. Get creative here!\n",
    "\n",
    "The EDA questions do not necessarily have to tie into the modeling part later on. Think freely about things that might be interesting, like which actors are very specific to a genre? Are action movies more prone to producing sequels than romances? However, as you keep the focus on movie genres, think also about correlations you might discover that can help build features from the metadata for prediction. Is the length of a movie title correlated with genre?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API code to access the genre and movie poster path of your favorite movie ('300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 73 posters.\n",
      "In TMDB movie database, the movie has the following genres:\n",
      "[u'Action', u'Adventure', u'War']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "CONFIG_PATTERN = 'http://api.themoviedb.org/3/configuration?api_key=352e668a0df90032e0f1097459228131'\n",
    "IMG_PATTERN = 'http://api.themoviedb.org/3/movie/{imdbid}/images?api_key=352e668a0df90032e0f1097459228131' \n",
    "DETAILS_PATTERN = 'https://api.themoviedb.org/3/movie/{imdbid}?api_key=352e668a0df90032e0f1097459228131'\n",
    "KEY = '352e668a0df90032e0f1097459228131'\n",
    "            \n",
    "def _get_json(url):\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n",
    "    \n",
    "def _download_images(urls, path='.'):\n",
    "    \"\"\"download all images in list 'urls' to 'path' \"\"\"\n",
    "\n",
    "    for nr, url in enumerate(urls):\n",
    "        r = requests.get(url)\n",
    "        filetype = r.headers['content-type'].split('/')[-1]\n",
    "        filename = 'poster_{0}.{1}'.format(nr+1,filetype)\n",
    "        filepath = os.path.join(path, filename)\n",
    "        with open(filepath,'wb') as w:\n",
    "            w.write(r.content)\n",
    "\n",
    "def get_poster_images(imdbid):\n",
    "    \"\"\" return image urls of posters and movie genres for IMDB id\n",
    "        returns all poster images from 'themoviedb.org'. Uses the\n",
    "        maximum available size. \n",
    "        Args:\n",
    "            imdbid (str): IMDB id of the movie\n",
    "        Returns:\n",
    "            list: list of urls to the images\n",
    "    \"\"\"\n",
    "    config = _get_json(CONFIG_PATTERN.format(key=KEY))\n",
    "    #print config\n",
    "    base_url = config['images']['base_url']\n",
    "    #print base_url\n",
    "    sizes = config['images']['poster_sizes']\n",
    "    #print sizes\n",
    "    \"\"\"\n",
    "        'sizes' should be sorted in ascending order, so\n",
    "            max_size = sizes[-1]\n",
    "        should get the largest size as well.        \n",
    "    \"\"\"\n",
    "    def size_str_to_int(x):\n",
    "        return float(\"inf\") if x == 'original' else int(x[1:])\n",
    "    max_size = max(sizes, key=size_str_to_int)\n",
    "    #print sizes\n",
    "    #print max_size\n",
    "    \n",
    "    # get posters (images)\n",
    "    posters = _get_json(IMG_PATTERN.format(key=KEY,imdbid=imdbid))['posters']\n",
    "    \n",
    "    poster_urls = []\n",
    "    count = 0\n",
    "    for poster in posters:\n",
    "        rel_path = poster['file_path']\n",
    "        url = \"{0}{1}{2}\".format(base_url, max_size, rel_path)\n",
    "        #print url\n",
    "        poster_urls.append(url)\n",
    "        count = count + 1\n",
    "    \n",
    "    print 'Downloaded ' + str(count) + ' posters.'\n",
    "\n",
    "    return poster_urls\n",
    "\n",
    "def get_movie_genres(imdbid):\n",
    "    \"\"\" return image urls of posters and movie genres for IMDB id\n",
    "        returns all poster images from 'themoviedb.org'. Uses the\n",
    "        maximum available size. \n",
    "        Args:\n",
    "            imdbid (str): IMDB id of the movie\n",
    "        Returns:\n",
    "            list: list of urls to the images\n",
    "    \"\"\"\n",
    "    config = _get_json(CONFIG_PATTERN.format(key=KEY))\n",
    "    #print config\n",
    "    base_url = config['images']['base_url']\n",
    "    #print base_url\n",
    "    sizes = config['images']['poster_sizes']\n",
    "    #print sizes\n",
    "    \"\"\"\n",
    "        'sizes' should be sorted in ascending order, so\n",
    "            max_size = sizes[-1]\n",
    "        should get the largest size as well.        \n",
    "    \"\"\"\n",
    "    def size_str_to_int(x):\n",
    "        return float(\"inf\") if x == 'original' else int(x[1:])\n",
    "    max_size = max(sizes, key=size_str_to_int)\n",
    "    #print sizes\n",
    "    #print max_size\n",
    "       \n",
    "    # get details (includes genres)\n",
    "    genres = _get_json(DETAILS_PATTERN.format(key=KEY,imdbid=imdbid))['genres']\n",
    "    \n",
    "    genres_lst = []\n",
    "    count = 0\n",
    "    for gen in genres:\n",
    "        g = gen['name']\n",
    "        genres_lst.append(g)\n",
    "        count = count + 1\n",
    "    \n",
    "    return genres_lst\n",
    "\n",
    "def tmdb_posters(imdbid, count=None, outpath='.'):    \n",
    "    urls = get_poster_images(imdbid)\n",
    "    \n",
    "    # get and print genres\n",
    "    genres = get_movie_genres(imdbid)\n",
    "    print 'In TMDB movie database, the movie has the following genres:'\n",
    "    print genres\n",
    "    \n",
    "    if count is not None:\n",
    "        urls = urls[:count]\n",
    "    _download_images(urls, outpath)\n",
    "\n",
    "#print __name__\n",
    "if __name__==\"__main__\":\n",
    "    #tmdb_posters('tt0095016')\n",
    "    \n",
    "    tmdb_posters('tt0416449')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'tt0416449'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "def imdb_id_from_title(title):\n",
    "    \"\"\" return IMDB id for search string\n",
    "\n",
    "        Args::\n",
    "            title (str): the movie title search string\n",
    "\n",
    "        Returns: \n",
    "            str. IMDB id, e.g., 'tt0095016' \n",
    "            None. If no match was found\n",
    "\n",
    "    \"\"\"\n",
    "    pattern = 'http://www.imdb.com/xml/find?json=1&nr=1&tt=on&q={movie_title}'\n",
    "    url = pattern.format(movie_title=urllib.quote(title))\n",
    "    r = requests.get(url)\n",
    "    res = r.json()\n",
    "    # sections in descending order or preference\n",
    "    for section in ['popular','exact','substring']:\n",
    "        key = 'title_' + section \n",
    "        if key in res:\n",
    "            return res[key][0]['id']\n",
    "        \n",
    "imdb_id_from_title('300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre entries of IMDb and TMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name IMDb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-4b81a728681c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlmdb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMDb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name IMDb"
     ]
    }
   ],
   "source": [
    "from lmdb import IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named IMDbPY",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-9cceb388eeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mIMDbPY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named IMDbPY"
     ]
    }
   ],
   "source": [
    "import IMDbPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 most popular movies on TMDb from 2016 with their genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Arrival': [u'Drama', u'Science Fiction'],\n",
       " u'Captain America: Civil War': [u'Action', u'Science Fiction'],\n",
       " u'Deadpool': [u'Action', u'Adventure', u'Comedy', u'Romance'],\n",
       " u'Doctor Strange': [u'Action', u'Adventure', u'Fantasy', u'Science Fiction'],\n",
       " u'Fantastic Beasts and Where to Find Them': [u'Adventure',\n",
       "  u'Action',\n",
       "  u'Fantasy'],\n",
       " u'Finding Dory': [u'Adventure', u'Animation', u'Comedy', u'Family'],\n",
       " u'Lion': [u'Drama'],\n",
       " u'Rogue One: A Star Wars Story': [u'Action',\n",
       "  u'Drama',\n",
       "  u'Science Fiction',\n",
       "  u'War'],\n",
       " u'Sing': [u'Animation', u'Comedy', u'Drama', u'Family', u'Music'],\n",
       " u'Underworld: Blood Wars': [u'Action', u'Horror']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOST_POPULAR = 'https://api.themoviedb.org/3/movie/popular?api_key=352e668a0df90032e0f1097459228131&language=en-US&page={page_num}'\n",
    "\n",
    "# page number\n",
    "pg_n = 1\n",
    "\n",
    "# number of movies we want\n",
    "max_num = 10\n",
    "\n",
    "# dict (key: movie, value: genre)\n",
    "popular_movies = {}\n",
    "\n",
    "done = False\n",
    "count = 0\n",
    "# find 10 movies, keep going through pages until found\n",
    "while not done:\n",
    "    # access API\n",
    "    popular = _get_json(MOST_POPULAR.format(page_num=pg_n))\n",
    "    \n",
    "    # cycle through movies in the page of most popular movies\n",
    "    for movie in popular['results']:\n",
    "        # get year movie was released\n",
    "        year = movie['release_date'].split(\"-\")[0]\n",
    "        \n",
    "        # if year was 2016, add entry to dict\n",
    "        if year == '2016' and count < max_num:\n",
    "            # get movie title and associated imdbid\n",
    "            title = movie['title']\n",
    "            imdbid = imdb_id_from_title(title)\n",
    "            \n",
    "            # get movie genres\n",
    "            genres = get_movie_genres(imdbid)\n",
    "            \n",
    "            # add to dict\n",
    "            popular_movies[title] = genres\n",
    "            \n",
    "            # increment counter\n",
    "            count += 1\n",
    "    \n",
    "    # move onto next page\n",
    "    pg_n += 1\n",
    "    \n",
    "    # break when found 10 movies\n",
    "    if count >= max_num:\n",
    "        done = True\n",
    "\n",
    "popular_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on what challenges you see for predicting movie genre based on the data you have, and how to address them\n",
    "\n",
    "1) There are differences in the genres listed by TMDb vs. IMDb\n",
    "    - We could use a union of the genres so that only those genres in both databases are considered correct\n",
    "2) The data will take a long time to load from the APIs because we need to restrict the rate at which we pull large amounts of data - ethics\n",
    "    - We need to work ahead and use AWS\n",
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 2: Assembling training data, due Wednesday, April 12, 2017\n",
    "\n",
    "We are aware that you have little time this week, due to the midterm. So this milestone is a bit easier to achieve than the others. The goal for this week is to prepare the data for the modeling phase of the project. You should end up with a typical data setup of training data X and data labels Y.\n",
    "\n",
    "The exact form of X and Y depends on the ideas you had previously. In general though Y should involve the genre of a movie, and X the features you want to include to predict the genre. Remember from the lecture that more features does not necessarily equal better prediction performance. Use your application knowledge and the insight you gathered from your genre pair analysis and additional EDA to design Y. Do you want to include all genres? Are there genres that you assume to be easier to separate than others? Are there genres that could be grouped together? There is no one right answer here. We are looking for your insight, so be sure to describe your decision process in your notebook. \n",
    "\n",
    "In preparation for the deep learning part we strongly encourage you to have two sets of training data X, one with the metadata and one with the movie posters. Make sure to have a common key, like the movie ID, to be able to link the two sets together. Also be mindful of the data rate when you obtain the posters. Time your requests and choose which poster resolution you need. In most cases w500 should be sufficient, and probably a lower resolution will be fine.\n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Discussion about the imbalanced nature of the data and how you want to address it\n",
    "- Description of your data\n",
    "- What does your choice of Y look like?\n",
    "- Which features do you choose for X and why? \n",
    "- How do you sample your data, how many samples, and why?\n",
    "\n",
    "*Important*: You do not need to upload the data itself to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 3: Traditional statistical and machine learning methods, due Wednesday, April 19, 2017\n",
    "\n",
    "Think about how you would address the genre prediction problem with traditional statistical or machine learning methods. This includes everything you learned about modeling in this course before the deep learning part. Implement your ideas and compare different classifiers. Report your results and discuss what challenges you faced and how you overcame them. What works and what does not? If there are parts that do not work as expected, make sure to discuss briefly what you think is the cause and how you would address this if you would have more time and resources. \n",
    "\n",
    "You do not necessarily need to use the movie posters for this step, but even without a background in computer vision, there are very simple features you can extract from the posters to help guide a traditional machine learning model. Think about the PCA lecture for example, or how to use clustering to extract color information. In addition to considering the movie posters it would be worthwhile to have a look at the metadata that IMDb provides. \n",
    "\n",
    "You could use Spark and the [ML library](https://spark.apache.org/docs/latest/ml-features.html#word2vec) to build your model features from the data. This may be especially beneficial if you use additional data, e.g., in text form.\n",
    "\n",
    "You also need to think about how you are going to evaluate your classifier. Which metrics or scores will you report to show how good the performance is?\n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Detailed description and implementation of two different models\n",
    "- Description of your performance metrics\n",
    "- Careful performance evaluations for both models\n",
    "- Visualizations of the metrics for performance evaluation\n",
    "- Discussion of the differences between the models, their strengths, weaknesses, etc. \n",
    "- Discussion of the performances you achieved, and how you might be able to improve them in the future\n",
    "\n",
    "#### Preliminary Peer Assessment\n",
    "\n",
    "It is important to provide positive feedback to people who truly worked hard for the good of the team and to also make suggestions to those you perceived not to be working as effectively on team tasks. We ask you to provide an honest assessment of the contributions of the members of your team, including yourself. The feedback you provide should reflect your judgment of each team member’s:\n",
    "\n",
    "- Preparation – were they prepared during team meetings?\n",
    "- Contribution – did they contribute productively to the team discussion and work?\n",
    "- Respect for others’ ideas – did they encourage others to contribute their ideas?\n",
    "- Flexibility – were they flexible when disagreements occurred?\n",
    "\n",
    "Your teammate’s assessment of your contributions and the accuracy of your self-assessment will be considered as part of your overall project score.\n",
    "\n",
    "Preliminary Peer Assessment: [https://goo.gl/forms/WOYC7pwRCSU0yV3l1](https://goo.gl/forms/WOYC7pwRCSU0yV3l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 4: Deep learning, due Wednesday, April 26, 2017\n",
    "\n",
    "For this milestone you will (finally) use deep learning to predict movie genres. You will train one small network from scratch on the posters only, and compare this one to a pre-trained network that you fine tune. [Here](https://keras.io/getting-started/faq/#how-can-i-use-pre-trained-models-in-keras) is a description of how to use pretrained models in Keras.\n",
    "\n",
    "You can try different architectures, initializations, parameter settings, optimization methods, etc. Be adventurous and explore deep learning! It can be fun to combine the features learned by the deep learning model with a SVM, or incorporate meta data into your deep learning model. \n",
    "\n",
    "**Note:** Be mindful of the longer training times for deep models. Not only for training time, but also for the parameter tuning efforts. You need time to develop a feel for the different parameters and which settings work, which normalization you want to use, which model architecture you choose, etc. \n",
    "\n",
    "It is great that we have GPUs via AWS to speed up the actual computation time, but you need to be mindful of your AWS credits. The GPU instances are not cheap and can accumulate costs rather quickly. Think about your model first and do some quick dry runs with a larger learning rate or large batch size on your local machine. \n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. \n",
    "- Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. \n",
    "- Discussion of the results, how much improvement you gained with fine tuning, etc. \n",
    "- Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 5: Final submission, report and screencast, due Wednesday, May 3, 2017\n",
    "\n",
    "The grand finale! Gather all your experiences, ideas, results, and discussions into one coherent final report that tells a compelling story and produce a 2 minute screencast that summarizes it. \n",
    "\n",
    "Your report needs to be max. 6 pages long (no more!) and include text and visualizations. Your audience are data scientists who did not spend any time pondering movie genre classification problems. Those data scientists do have the same background as you (e.g., you do not need to explain what PCA means) but they are not familiar with your data and the specific problems and questions you faced. Make sure to use good storytelling principles to write your reports. \n",
    "\n",
    "The screencast is for the same audience and needs to be max. 2 minutes long (no longer!). Do not just scroll through your notebook while talking--that is boring and confusing. You can extract visualizations from your notebook or produce new visuals and slides for a narrated presentation. Please use a good microphone and test the sound quality. Do not underestimate the time it takes to do a good job on your screencast. Start early, write a script, and collect additional materials that you might want to show. \n",
    "\n",
    "[Upload](https://support.google.com/youtube/answer/57407?co=GENIE.Platform%3DDesktop&hl=en) your screenscast to YouTube.\n",
    "\n",
    "What to submit this week:\n",
    "\n",
    "- Up to date versions of all your notebooks\n",
    "- README to go with the notebooks that explains how much the notebooks changed since the milestone submissions. This is to guide your TF to find the relevant updates\n",
    "- The 6 page final report as a PDF\n",
    "- The link to your 2 minute screencast on YouTube\n",
    "- A link to a .zip file with all your cleaned data\n",
    "\n",
    "#### Final Peer Assessment\n",
    "\n",
    "It is important to provide positive feedback to people who truly worked hard for the good of the team and to also make suggestions to those you perceived not to be working as effectively on team tasks. We ask you to provide an honest assessment of the contributions of the members of your team, including yourself. The feedback you provide should reflect your judgment of each team member’s:\n",
    "\n",
    "- Preparation – were they prepared during team meetings?\n",
    "- Contribution – did they contribute productively to the team discussion and work?\n",
    "- Respect for others’ ideas – did they encourage others to contribute their ideas?\n",
    "- Flexibility – were they flexible when disagreements occurred?\n",
    "\n",
    "Your teammate’s assessment of your contributions and the accuracy of your self-assessment will be considered as part of your overall project score.\n",
    "\n",
    "Final Peer Assessment: [https://goo.gl/forms/YYFqGbDEfFWeNaSC2](https://goo.gl/forms/YYFqGbDEfFWeNaSC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
