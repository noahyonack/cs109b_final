{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 4: Deep learning, due Wednesday, April 26, 2017\n",
    "\n",
    "For this milestone you will (finally) use deep learning to predict movie genres. You will train one small network from scratch on the posters only, and compare this one to a pre-trained network that you fine tune. [Here](https://keras.io/getting-started/faq/#how-can-i-use-pre-trained-models-in-keras) is a description of how to use pretrained models in Keras.\n",
    "\n",
    "You can try different architectures, initializations, parameter settings, optimization methods, etc. Be adventurous and explore deep learning! It can be fun to combine the features learned by the deep learning model with a SVM, or incorporate meta data into your deep learning model. \n",
    "\n",
    "**Note:** Be mindful of the longer training times for deep models. Not only for training time, but also for the parameter tuning efforts. You need time to develop a feel for the different parameters and which settings work, which normalization you want to use, which model architecture you choose, etc. \n",
    "\n",
    "It is great that we have GPUs via AWS to speed up the actual computation time, but you need to be mindful of your AWS credits. The GPU instances are not cheap and can accumulate costs rather quickly. Think about your model first and do some quick dry runs with a larger learning rate or large batch size on your local machine. \n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. \n",
    "- Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. \n",
    "- Discussion of the results, how much improvement you gained with fine tuning, etc. \n",
    "- Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# for image manipulation. Easier to do \n",
    "# here than with Keras, as per\n",
    "# https://piazza.com/class/ivlbdd3nigy3um?cid=818\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step One: Extracting Movies From URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_thinned shape: (540, 29)\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv(\"train_full.csv\")\n",
    "# train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "# print \"Train shape:\", train.shape\n",
    "# train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_thinned shape: (540, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10402</th>\n",
       "      <th>10749</th>\n",
       "      <th>10751</th>\n",
       "      <th>10752</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>lead actors</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[u'Alec Baldwin', u'Miles Bakshi', u'Jimmy Kim...</td>\n",
       "      <td>295693</td>\n",
       "      <td>A story about how a new baby's arrival impacts...</td>\n",
       "      <td>305.881041</td>\n",
       "      <td>/unPB1iyEeTBcKiLg8W083rlViFH.jpg</td>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>The Boss Baby</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10402  10749  10751  10752  12  14  16  18  27  28    ...      \\\n",
       "0      0      0      1      0   0   0   1   0   0   0    ...       \n",
       "\n",
       "                                         lead actors  movie_id  \\\n",
       "0  [u'Alec Baldwin', u'Miles Bakshi', u'Jimmy Kim...    295693   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  A story about how a new baby's arrival impacts...  305.881041   \n",
       "\n",
       "                        poster_path  release_date          title  video  \\\n",
       "0  /unPB1iyEeTBcKiLg8W083rlViFH.jpg    2017-03-23  The Boss Baby  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          5.7        510  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_thinned = pd.read_csv(\"train.csv\")\n",
    "train_thinned.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "print \"train_thinned shape:\", train_thinned.shape\n",
    "train_thinned.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Important. \n",
    "\n",
    "The line below aliases the DF that we want to work with as `curr_df`. When we decide later on to use the full training set instead of just `train_thinned`, all we need to do is set it in the cell below and re-run the code. This will prevent us from having to find/replace all instances of the past dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "curr_df = train_thinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Helper that downloads web images \n",
    "## Takes in the poster path and the id of the movie \n",
    "## Saves the movie as a jpg as the unique id of the movie \n",
    "## In the images folder.\n",
    "def download_web_image(poster_path, movie_id):\n",
    "    # given that we're going to resize our images to be 32x32\n",
    "    # or something else really small, let's download really small images \n",
    "    # to start\n",
    "    base_url = \"https://image.tmdb.org/t/p/w92/\" \n",
    "    \n",
    "    request = urllib2.Request(base_url + poster_path)\n",
    "    img = urllib2.urlopen(request).read()\n",
    "    image_name= \"images/\" + str(movie_id) + \".jpg\"\n",
    "    \n",
    "    with open(image_name, 'w') as f: \n",
    "        f.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you actually want to download posters, you'll need to turn the `1` above into a `0`. This code doesn't run by default in the notebook so that you don't accidentally download hundreds of images.\n"
     ]
    }
   ],
   "source": [
    "### iterate through all of the images in the thinned dataset, saving locally \n",
    "if 1:\n",
    "    print \"If you actually want to download posters, you'll need to turn the `1` above into a `0`. This code doesn't run by default in the notebook so that you don't accidentally download hundreds of images.\"\n",
    "else:\n",
    "    for index, row in curr_df.iterrows():\n",
    "        movie_id = row[\"movie_id\"]\n",
    "        poster_path = row[\"poster_path\"] \n",
    "#         download_web_image(poster_path, movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "# convert each normal poster to a 32x32 grayscale poster\n",
    "for img_name in os.listdir(\"images/\"):\n",
    "    # read in an image and convert to greyscale\n",
    "    im = Image.open(\"images/\" + img_name).convert(\"L\")\n",
    "    out = im.resize((img_rows, img_cols))\n",
    "    out.save(\"nn_ready_images/\" + img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building a CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of labels in our output\n",
    "n_labels = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now we need training and testing data. in the current state,\n",
    "# we have a bunch of greyscale images named by their movie ids.\n",
    "# to get the data, we can first just split all the movie ids (X) in the\n",
    "# dataframe intro train and test sets, and then grab their multilabel\n",
    "# matrices (y)\n",
    "m_ids = curr_df.movie_id.values\n",
    "\n",
    "# shuffle the ids to get a random sample\n",
    "np.random.shuffle(m_ids)\n",
    "\n",
    "import math\n",
    "train_size = int(math.floor(.7 * len(m_ids)))\n",
    "\n",
    "# get the movie_ids (each of which has an image in \"nn_images_ready/\"\n",
    "# which is ready to be put through the neural net\n",
    "train_ids = m_ids[:train_size]\n",
    "test_ids = m_ids[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (378, 17)\n",
      "y_test shape: (162, 17)\n"
     ]
    }
   ],
   "source": [
    "# these are the column names of the multilabel matrix\n",
    "label_names = curr_df.columns[:n_labels]\n",
    "\n",
    "y_train = np.array([curr_df[curr_df.movie_id == movie_id][label_names].values[0] for movie_id in train_ids])\n",
    "y_test  = np.array([curr_df[curr_df.movie_id == movie_id][label_names].values[0] for movie_id in test_ids])\n",
    "\n",
    "# should be (num_samples, num_labels)\n",
    "print \"y_train shape:\", y_train.shape\n",
    "print \"y_test shape:\", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# smaller batch size means noisier gradient, but more updates per epoch\n",
    "batch_size = 512\n",
    "\n",
    "# number of iterations over the complete training data\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load image matrices into memory\n",
    "x_train = np.array([np.asarray(Image.open(\"nn_ready_images/\" + str(m_id) + \".jpg\")) for m_id in train_ids])\n",
    "x_test =  np.array([np.asarray(Image.open(\"nn_ready_images/\" + str(m_id) + \".jpg\")) for m_id in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (378, 64, 64)\n",
      "x_test shape: (162, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# output should be (num_images, img_height, img_width)\n",
    "print \"x_train shape:\", x_train.shape\n",
    "print \"x_test shape:\", x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (378, 64, 64, 1)\n",
      "378 train samples\n",
      "162 test samples\n"
     ]
    }
   ],
   "source": [
    "# code borrowed from Keras_CNN lab\n",
    "\n",
    "# now we need to reshape x_train and x_test so that they work with CNNs\n",
    "# Following the example in \"labs/Keras_CNN.ipynb\", this needs to be an array \n",
    "# of images with shape determined by the backend, including the depth dimension,\n",
    "# which is 1 for greyscale\n",
    "\n",
    "# x_train is of shape n_samples x 32 x 32\n",
    "# for a CNN we want to keep the image shape\n",
    "# need to explicitly tell keras that it is a gray value image\n",
    "# so each image is 32x32x1 not 32x32x3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# normalize image values to [0,1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print \"x_train shape:\", x_train.shape\n",
    "print x_train.shape[0], \"train samples\"\n",
    "print x_test.shape[0], \"test samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 17)                1105      \n",
      "=================================================================\n",
      "Total params: 172,177.0\n",
      "Trainable params: 172,177.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model = Sequential()\n",
    "\n",
    "# define the input layer to the CNN\n",
    "# input shape is a tuple of the # rows, # cols, and # channels (1 for grayscale)\n",
    "# the first parameter to Conv2D is the number of filters we want to convolve\n",
    "# over the input images\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add another convolution layer\n",
    "# we could double the number of filters as max pool made the \n",
    "# feature maps much smaller, but we're not doing this to improve runtime\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# ================\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# ================\n",
    "\n",
    "# flatten for fully connected classification layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# note that the 10 is the number of classes we have\n",
    "# the classes are mutually exclusive so softmax is a good choice\n",
    "# --- fully connected layer ---\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# recommended by: https://github.com/fchollet/keras/issues/761\n",
    "# uses a sigmoid activation rather than softmax, which apparently\n",
    "# gives us a label vector back\n",
    "model.add(Dense(n_labels, activation='sigmoid'))\n",
    "\n",
    "# prints out a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "Let's use a large learning rate (0.1) while we're working locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the setup is our basic categorical crossentropy with stochastic gradient decent\n",
    "# we also specify that we want to evaluate our model in terms of accuracy\n",
    "sgd = SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# TODO: why are we using binary crossentropy?\n",
    "# I'm not sure, but it works much better than\n",
    "# categorical crossentropy.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378 samples, validate on 162 samples\n",
      "Epoch 1/30\n",
      "378/378 [==============================] - 3s - loss: 0.7027 - acc: 0.3901 - val_loss: 0.6960 - val_acc: 0.4444\n",
      "Epoch 2/30\n",
      "378/378 [==============================] - 2s - loss: 0.6968 - acc: 0.4494 - val_loss: 0.6872 - val_acc: 0.5251\n",
      "Epoch 3/30\n",
      "378/378 [==============================] - 2s - loss: 0.6876 - acc: 0.5472 - val_loss: 0.6785 - val_acc: 0.6176\n",
      "Epoch 4/30\n",
      "378/378 [==============================] - 2s - loss: 0.6787 - acc: 0.6306 - val_loss: 0.6701 - val_acc: 0.6681\n",
      "Epoch 5/30\n",
      "378/378 [==============================] - 2s - loss: 0.6702 - acc: 0.6839 - val_loss: 0.6585 - val_acc: 0.7186\n",
      "Epoch 6/30\n",
      "378/378 [==============================] - 2s - loss: 0.6586 - acc: 0.7359 - val_loss: 0.6414 - val_acc: 0.7571\n",
      "Epoch 7/30\n",
      "378/378 [==============================] - 2s - loss: 0.6413 - acc: 0.7670 - val_loss: 0.6163 - val_acc: 0.7582\n",
      "Epoch 8/30\n",
      "378/378 [==============================] - 2s - loss: 0.6161 - acc: 0.7705 - val_loss: 0.5841 - val_acc: 0.7578\n",
      "Epoch 9/30\n",
      "378/378 [==============================] - 2s - loss: 0.5834 - acc: 0.7705 - val_loss: 0.5558 - val_acc: 0.7778\n",
      "Epoch 10/30\n",
      "378/378 [==============================] - 2s - loss: 0.5540 - acc: 0.7916 - val_loss: 0.5351 - val_acc: 0.7988\n",
      "Epoch 11/30\n",
      "378/378 [==============================] - 2s - loss: 0.5321 - acc: 0.8106 - val_loss: 0.5072 - val_acc: 0.8028\n",
      "Epoch 12/30\n",
      "378/378 [==============================] - 2s - loss: 0.5032 - acc: 0.8119 - val_loss: 0.4861 - val_acc: 0.8293\n",
      "Epoch 13/30\n",
      "378/378 [==============================] - 2s - loss: 0.4752 - acc: 0.8265 - val_loss: 0.4961 - val_acc: 0.8072\n",
      "Epoch 14/30\n",
      "378/378 [==============================] - 3s - loss: 0.4738 - acc: 0.8031 - val_loss: 0.5120 - val_acc: 0.7996\n",
      "Epoch 15/30\n",
      "378/378 [==============================] - 2s - loss: 0.4796 - acc: 0.7989 - val_loss: 0.4708 - val_acc: 0.8039\n",
      "Epoch 16/30\n",
      "378/378 [==============================] - 2s - loss: 0.4394 - acc: 0.8111 - val_loss: 0.4376 - val_acc: 0.7988\n",
      "Epoch 17/30\n",
      "378/378 [==============================] - 2s - loss: 0.4152 - acc: 0.8111 - val_loss: 0.4404 - val_acc: 0.8014\n",
      "Epoch 18/30\n",
      "378/378 [==============================] - 2s - loss: 0.4261 - acc: 0.8112 - val_loss: 0.4455 - val_acc: 0.8025\n",
      "Epoch 19/30\n",
      "378/378 [==============================] - 2s - loss: 0.4368 - acc: 0.8126 - val_loss: 0.4415 - val_acc: 0.8079\n",
      "Epoch 20/30\n",
      "378/378 [==============================] - 3s - loss: 0.4357 - acc: 0.8157 - val_loss: 0.4330 - val_acc: 0.8257\n",
      "Epoch 21/30\n",
      "378/378 [==============================] - 3s - loss: 0.4282 - acc: 0.8237 - val_loss: 0.4225 - val_acc: 0.8243\n",
      "Epoch 22/30\n",
      "378/378 [==============================] - 3s - loss: 0.4173 - acc: 0.8234 - val_loss: 0.4148 - val_acc: 0.8243\n",
      "Epoch 23/30\n",
      "378/378 [==============================] - 3s - loss: 0.4080 - acc: 0.8249 - val_loss: 0.4139 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "378/378 [==============================] - 3s - loss: 0.4047 - acc: 0.8265 - val_loss: 0.4173 - val_acc: 0.8293\n",
      "Epoch 25/30\n",
      "378/378 [==============================] - 2s - loss: 0.4057 - acc: 0.8265 - val_loss: 0.4185 - val_acc: 0.8293\n",
      "Epoch 26/30\n",
      "378/378 [==============================] - 2s - loss: 0.4055 - acc: 0.8265 - val_loss: 0.4161 - val_acc: 0.8293\n",
      "Epoch 27/30\n",
      "378/378 [==============================] - 3s - loss: 0.4030 - acc: 0.8265 - val_loss: 0.4133 - val_acc: 0.8297\n",
      "Epoch 28/30\n",
      "378/378 [==============================] - 2s - loss: 0.4010 - acc: 0.8265 - val_loss: 0.4121 - val_acc: 0.8290\n",
      "Epoch 29/30\n",
      "378/378 [==============================] - 2s - loss: 0.4008 - acc: 0.8263 - val_loss: 0.4117 - val_acc: 0.8297\n",
      "Epoch 30/30\n",
      "378/378 [==============================] - 4s - loss: 0.4013 - acc: 0.8266 - val_loss: 0.4107 - val_acc: 0.8293\n"
     ]
    }
   ],
   "source": [
    "# this is now the actual training\n",
    "# in addition to the training data we provide validation data\n",
    "# this data is used to calculate the performance of the model over all the epochs\n",
    "# this is useful to determine when training should stop\n",
    "# in our case we just use it to monitor the evolution of the model over the training epochs\n",
    "# if we use the validation data to determine when to stop the training or which model to save, we \n",
    "# should not use the test data, but a separate validation set. \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.41069724272798608)\n",
      "('Test accuracy:', 0.82933911717968223)\n"
     ]
    }
   ],
   "source": [
    "# once training is complete, let's see how well we have done\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f99083122d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGDCAYAAAAyM4nNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f990883c3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title(\"Accuracy as a function of epochs\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
