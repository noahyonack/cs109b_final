{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 4: Deep learning, due Wednesday, April 26, 2017\n",
    "\n",
    "For this milestone you will (finally) use deep learning to predict movie genres. You will train one small network from scratch on the posters only, and compare this one to a pre-trained network that you fine tune. [Here](https://keras.io/getting-started/faq/#how-can-i-use-pre-trained-models-in-keras) is a description of how to use pretrained models in Keras.\n",
    "\n",
    "You can try different architectures, initializations, parameter settings, optimization methods, etc. Be adventurous and explore deep learning! It can be fun to combine the features learned by the deep learning model with a SVM, or incorporate meta data into your deep learning model. \n",
    "\n",
    "**Note:** Be mindful of the longer training times for deep models. Not only for training time, but also for the parameter tuning efforts. You need time to develop a feel for the different parameters and which settings work, which normalization you want to use, which model architecture you choose, etc. \n",
    "\n",
    "It is great that we have GPUs via AWS to speed up the actual computation time, but you need to be mindful of your AWS credits. The GPU instances are not cheap and can accumulate costs rather quickly. Think about your model first and do some quick dry runs with a larger learning rate or large batch size on your local machine. \n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. \n",
    "- Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. \n",
    "- Discussion of the results, how much improvement you gained with fine tuning, etc. \n",
    "- Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# for image manipulation. Easier to do \n",
    "# here than with Keras, as per\n",
    "# https://piazza.com/class/ivlbdd3nigy3um?cid=818\n",
    "#!sudo pip install Image\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step One: Extracting Movies From URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"train_full.csv\")\n",
    "# train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "# print \"Train shape:\", train.shape\n",
    "# train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_thinned shape: (540, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10402</th>\n",
       "      <th>10749</th>\n",
       "      <th>10751</th>\n",
       "      <th>10752</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>lead actors</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[u'Alec Baldwin', u'Miles Bakshi', u'Jimmy Kim...</td>\n",
       "      <td>295693</td>\n",
       "      <td>A story about how a new baby's arrival impacts...</td>\n",
       "      <td>305.881041</td>\n",
       "      <td>/unPB1iyEeTBcKiLg8W083rlViFH.jpg</td>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>The Boss Baby</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10402  10749  10751  10752  12  14  16  18  27  28    ...      \\\n",
       "0      0      0      1      0   0   0   1   0   0   0    ...       \n",
       "\n",
       "                                         lead actors  movie_id  \\\n",
       "0  [u'Alec Baldwin', u'Miles Bakshi', u'Jimmy Kim...    295693   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  A story about how a new baby's arrival impacts...  305.881041   \n",
       "\n",
       "                        poster_path  release_date          title  video  \\\n",
       "0  /unPB1iyEeTBcKiLg8W083rlViFH.jpg    2017-03-23  The Boss Baby  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          5.7        510  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_thinned = pd.read_csv(\"train.csv\")\n",
    "train_thinned.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "print \"train_thinned shape:\", train_thinned.shape\n",
    "train_thinned.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Important. \n",
    "\n",
    "The line below aliases the DF that we want to work with as `curr_df`. When we decide later on to use the full training set instead of just `train_thinned`, all we need to do is set it in the cell below and re-run the code. This will prevent us from having to find/replace all instances of the past dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "curr_df = train_thinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Helper that downloads web images \n",
    "## Takes in the poster path and the id of the movie \n",
    "## Saves the movie as a jpg as the unique id of the movie \n",
    "## In the images folder.\n",
    "def download_web_image(poster_path, movie_id):\n",
    "    # given that we're going to resize our images to be 32x32\n",
    "    # or something else really small, let's download really small images \n",
    "    # to start\n",
    "    base_url = \"https://image.tmdb.org/t/p/w92/\" \n",
    "    \n",
    "    request = urllib2.Request(base_url + poster_path)\n",
    "    img = urllib2.urlopen(request).read()\n",
    "    image_name= \"images/\" + str(movie_id) + \".jpg\"\n",
    "    \n",
    "    with open(image_name, 'w') as f: \n",
    "        f.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you actually want to download posters, you'll need to turn the `1` above into a `0`. This code doesn't run by default in the notebook so that you don't accidentally download hundreds of images.\n"
     ]
    }
   ],
   "source": [
    "### iterate through all of the images in the thinned dataset, saving locally \n",
    "if 1:\n",
    "    print \"If you actually want to download posters, you'll need to turn the `1` above into a `0`. This code doesn't run by default in the notebook so that you don't accidentally download hundreds of images.\"\n",
    "else:\n",
    "    for index, row in curr_df.iterrows():\n",
    "        movie_id = row[\"movie_id\"]\n",
    "        poster_path = row[\"poster_path\"] \n",
    "#         download_web_image(poster_path, movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# convert each normal poster to a 32x32 grayscale poster\n",
    "for img_name in os.listdir(\"images/\"):\n",
    "    ## This line added to avoid hidden files on mac (Stephen)\n",
    "    if not img_name.startswith('.'):\n",
    "        # read in an image and convert to greyscale\n",
    "        im = Image.open(\"images/\" + img_name).convert(\"L\")\n",
    "        out = im.resize((img_rows, img_cols))\n",
    "        out.save(\"nn_ready_images/\" + img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Building a CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of labels in our output\n",
    "n_labels = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now we need training and testing data. in the current state,\n",
    "# we have a bunch of greyscale images named by their movie ids.\n",
    "# to get the data, we can first just split all the movie ids (X) in the\n",
    "# dataframe intro train and test sets, and then grab their multilabel\n",
    "# matrices (y)\n",
    "m_ids = curr_df.movie_id.values\n",
    "\n",
    "# shuffle the ids to get a random sample\n",
    "np.random.shuffle(m_ids)\n",
    "\n",
    "import math\n",
    "train_size = int(math.floor(.7 * len(m_ids)))\n",
    "\n",
    "# get the movie_ids (each of which has an image in \"nn_images_ready/\"\n",
    "# which is ready to be put through the neural net\n",
    "train_ids = m_ids[:train_size]\n",
    "test_ids = m_ids[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (378, 17)\n",
      "y_test shape: (162, 17)\n"
     ]
    }
   ],
   "source": [
    "# these are the column names of the multilabel matrix\n",
    "label_names = curr_df.columns[:n_labels]\n",
    "\n",
    "y_train = np.array([curr_df[curr_df.movie_id == movie_id][label_names].values[0] for movie_id in train_ids])\n",
    "y_test  = np.array([curr_df[curr_df.movie_id == movie_id][label_names].values[0] for movie_id in test_ids])\n",
    "\n",
    "# should be (num_samples, num_labels)\n",
    "print \"y_train shape:\", y_train.shape\n",
    "print \"y_test shape:\", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# smaller batch size means noisier gradient, but more updates per epoch\n",
    "batch_size = 512\n",
    "\n",
    "# number of iterations over the complete training data\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load image matrices into memory\n",
    "x_train = np.array([np.asarray(Image.open(\"nn_ready_images/\" + str(m_id) + \".jpg\")) for m_id in train_ids])\n",
    "x_test =  np.array([np.asarray(Image.open(\"nn_ready_images/\" + str(m_id) + \".jpg\")) for m_id in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (378, 32, 32)\n",
      "x_test shape: (162, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# output should be (num_images, img_height, img_width)\n",
    "print \"x_train shape:\", x_train.shape\n",
    "print \"x_test shape:\", x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 387072 into shape (378,299,299,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f5f9d8d129a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 387072 into shape (378,299,299,1)"
     ]
    }
   ],
   "source": [
    "# code borrowed from Keras_CNN lab\n",
    "\n",
    "# now we need to reshape x_train and x_test so that they work with CNNs\n",
    "# Following the example in \"labs/Keras_CNN.ipynb\", this needs to be an array \n",
    "# of images with shape determined by the backend, including the depth dimension,\n",
    "# which is 1 for greyscale\n",
    "\n",
    "# x_train is of shape n_samples x 32 x 32\n",
    "# for a CNN we want to keep the image shape\n",
    "# need to explicitly tell keras that it is a gray value image\n",
    "# so each image is 32x32x1 not 32x32x3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# normalize image values to [0,1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print \"x_train shape:\", x_train.shape\n",
    "print x_train.shape[0], \"train samples\"\n",
    "print x_test.shape[0], \"test samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a545c34bd06d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# the first parameter to Conv2D is the number of filters we want to convolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# over the input images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# create a max pooling layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model = Sequential()\n",
    "\n",
    "# define the input layer to the CNN\n",
    "# input shape is a tuple of the # rows, # cols, and # channels (1 for grayscale)\n",
    "# the first parameter to Conv2D is the number of filters we want to convolve\n",
    "# over the input images\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add another convolution layer\n",
    "# we could double the number of filters as max pool made the \n",
    "# feature maps much smaller, but we're not doing this to improve runtime\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# ================\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# ================\n",
    "\n",
    "# flatten for fully connected classification layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# note that the 10 is the number of classes we have\n",
    "# the classes are mutually exclusive so softmax is a good choice\n",
    "# --- fully connected layer ---\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# recommended by: https://github.com/fchollet/keras/issues/761\n",
    "# uses a sigmoid activation rather than softmax, which apparently\n",
    "# gives us a label vector back\n",
    "model.add(Dense(n_labels, activation='sigmoid'))\n",
    "\n",
    "# prints out a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "Let's use a large learning rate (0.1) while we're working locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the setup is our basic categorical crossentropy with stochastic gradient decent\n",
    "# we also specify that we want to evaluate our model in terms of accuracy\n",
    "sgd = SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# TODO: why are we using binary crossentropy?\n",
    "# I'm not sure, but it works much better than\n",
    "# categorical crossentropy.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378 samples, validate on 162 samples\n",
      "Epoch 1/30\n",
      "378/378 [==============================] - 1s - loss: 0.6857 - acc: 0.5893 - val_loss: 0.6808 - val_acc: 0.6264\n",
      "Epoch 2/30\n",
      "378/378 [==============================] - 0s - loss: 0.6793 - acc: 0.6513 - val_loss: 0.6685 - val_acc: 0.6743\n",
      "Epoch 3/30\n",
      "378/378 [==============================] - 0s - loss: 0.6670 - acc: 0.6945 - val_loss: 0.6497 - val_acc: 0.7019\n",
      "Epoch 4/30\n",
      "378/378 [==============================] - 0s - loss: 0.6486 - acc: 0.7163 - val_loss: 0.6224 - val_acc: 0.7190\n",
      "Epoch 5/30\n",
      "378/378 [==============================] - 1s - loss: 0.6216 - acc: 0.7155 - val_loss: 0.5816 - val_acc: 0.7858\n",
      "Epoch 6/30\n",
      "378/378 [==============================] - 1s - loss: 0.5815 - acc: 0.7786 - val_loss: 0.5246 - val_acc: 0.8199\n",
      "Epoch 7/30\n",
      "378/378 [==============================] - 1s - loss: 0.5252 - acc: 0.8008 - val_loss: 0.4715 - val_acc: 0.8199\n",
      "Epoch 8/30\n",
      "378/378 [==============================] - 0s - loss: 0.4715 - acc: 0.8013 - val_loss: 0.4665 - val_acc: 0.8210\n",
      "Epoch 9/30\n",
      "378/378 [==============================] - 1s - loss: 0.4594 - acc: 0.8038 - val_loss: 0.5116 - val_acc: 0.8293\n",
      "Epoch 10/30\n",
      "378/378 [==============================] - 1s - loss: 0.4826 - acc: 0.8265 - val_loss: 0.5728 - val_acc: 0.8021\n",
      "Epoch 11/30\n",
      "378/378 [==============================] - 0s - loss: 0.5131 - acc: 0.8120 - val_loss: 0.5785 - val_acc: 0.7821\n",
      "Epoch 12/30\n",
      "378/378 [==============================] - 0s - loss: 0.5106 - acc: 0.8059 - val_loss: 0.5040 - val_acc: 0.8086\n",
      "Epoch 13/30\n",
      "378/378 [==============================] - 0s - loss: 0.4607 - acc: 0.8171 - val_loss: 0.4541 - val_acc: 0.8290\n",
      "Epoch 14/30\n",
      "378/378 [==============================] - 0s - loss: 0.4408 - acc: 0.8265 - val_loss: 0.4467 - val_acc: 0.7898\n",
      "Epoch 15/30\n",
      "378/378 [==============================] - 0s - loss: 0.4482 - acc: 0.7723 - val_loss: 0.4313 - val_acc: 0.8010\n",
      "Epoch 16/30\n",
      "378/378 [==============================] - 0s - loss: 0.4358 - acc: 0.7812 - val_loss: 0.4233 - val_acc: 0.8315\n",
      "Epoch 17/30\n",
      "378/378 [==============================] - 0s - loss: 0.4256 - acc: 0.8284 - val_loss: 0.4244 - val_acc: 0.8083\n",
      "Epoch 18/30\n",
      "378/378 [==============================] - 2s - loss: 0.4230 - acc: 0.8181 - val_loss: 0.4256 - val_acc: 0.8061\n",
      "Epoch 19/30\n",
      "378/378 [==============================] - 1s - loss: 0.4203 - acc: 0.8145 - val_loss: 0.4253 - val_acc: 0.7988\n",
      "Epoch 20/30\n",
      "378/378 [==============================] - 1s - loss: 0.4166 - acc: 0.8106 - val_loss: 0.4264 - val_acc: 0.7988\n",
      "Epoch 21/30\n",
      "378/378 [==============================] - 1s - loss: 0.4149 - acc: 0.8112 - val_loss: 0.4292 - val_acc: 0.8199\n",
      "Epoch 22/30\n",
      "378/378 [==============================] - 1s - loss: 0.4158 - acc: 0.8190 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 23/30\n",
      "378/378 [==============================] - 0s - loss: 0.4161 - acc: 0.8190 - val_loss: 0.4280 - val_acc: 0.8199\n",
      "Epoch 24/30\n",
      "378/378 [==============================] - 0s - loss: 0.4131 - acc: 0.8193 - val_loss: 0.4238 - val_acc: 0.8293\n",
      "Epoch 25/30\n",
      "378/378 [==============================] - 0s - loss: 0.4088 - acc: 0.8265 - val_loss: 0.4207 - val_acc: 0.8290\n",
      "Epoch 26/30\n",
      "378/378 [==============================] - 0s - loss: 0.4059 - acc: 0.8266 - val_loss: 0.4195 - val_acc: 0.8290\n",
      "Epoch 27/30\n",
      "378/378 [==============================] - 0s - loss: 0.4051 - acc: 0.8265 - val_loss: 0.4193 - val_acc: 0.8293\n",
      "Epoch 28/30\n",
      "378/378 [==============================] - 1s - loss: 0.4054 - acc: 0.8265 - val_loss: 0.4186 - val_acc: 0.8293\n",
      "Epoch 29/30\n",
      "378/378 [==============================] - 1s - loss: 0.4051 - acc: 0.8265 - val_loss: 0.4169 - val_acc: 0.8293\n",
      "Epoch 30/30\n",
      "378/378 [==============================] - 1s - loss: 0.4036 - acc: 0.8265 - val_loss: 0.4149 - val_acc: 0.8293\n"
     ]
    }
   ],
   "source": [
    "# this is now the actual training\n",
    "# in addition to the training data we provide validation data\n",
    "# this data is used to calculate the performance of the model over all the epochs\n",
    "# this is useful to determine when training should stop\n",
    "# in our case we just use it to monitor the evolution of the model over the training epochs\n",
    "# if we use the validation data to determine when to stop the training or which model to save, we \n",
    "# should not use the test data, but a separate validation set. \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.69265439480911062)\n",
      "('Test accuracy:', 0.54357300275637777)\n"
     ]
    }
   ],
   "source": [
    "# once training is complete, let's see how well we have done\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f719de98e90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGDCAYAAAAs+rl+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngmBjvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f719dedc910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title(\"Accuracy as a function of epochs\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ToDos for #1\n",
    "1. Binary Categorization?\n",
    "2. Accuracy?\n",
    "3. Last layer for doing multilabel (is sigmoid correct?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Fine tuning a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Images to Format for InceptionV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Because inception takes in a 299 x 299 RGB image, we need to download them as such \n",
    "img_rows, img_cols = 299, 299\n",
    "\n",
    "# convert each normal poster to a 299x299 poster\n",
    "for img_name in os.listdir(\"images/\"):\n",
    "    if not img_name.startswith('.'):\n",
    "        # read in an image, do not convert to greyscale \n",
    "        im = Image.open(\"images/\" + img_name)\n",
    "        out = im.resize((img_rows, img_cols))\n",
    "        ## save to the inception images folder \n",
    "        out.save(\"inception_ready_images/\" + img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load image matrices into memory\n",
    "x_train = np.array([np.asarray(Image.open(\"inception_ready_images/\" + str(m_id) + \".jpg\")) for m_id in train_ids])\n",
    "x_test =  np.array([np.asarray(Image.open(\"inception_ready_images/\" + str(m_id) + \".jpg\")) for m_id in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 299, 299, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Our data is of the format that we can use for inception \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 299, 299, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert data into tuple of training data\n",
    "## model.fit_generator takes a tuple \n",
    "training = (x_train, y_train)\n",
    "\n",
    "test = (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights= 'imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(n_labels, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "# model.fit_generator(x_train, y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 299, 299, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## http://stackoverflow.com/questions/40574386/keras-model-fit-generator \n",
    "## This, in theory should generate the data in a way that we want. \n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(x_train[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 22s - loss: 0.5129 - acc: 0.8000 - val_loss: 0.4404 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 21s - loss: 0.5318 - acc: 0.8176 - val_loss: 0.4441 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 22s - loss: 0.5530 - acc: 0.8059 - val_loss: 0.4524 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bb2f710>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check out the validation set on this \n",
    "### SHOULD BE CHANGED TO VALIDATION SET \n",
    "model.fit_generator(datagen.flow(x_train[0:20], y_train[0:20], batch_size = 1), steps_per_epoch = 10, epochs = 3, validation_data=(x_test[0:20], y_test[:20]))\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "# model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "#                     steps_per_epoch=len(X_train) / 32, epochs=epochs)\n",
    "\n",
    "# ## Might need to use this generator \n",
    "\n",
    "# train_datagen = ImageDataGenerator()\n",
    "\n",
    "# train_datagen.fit\n",
    "\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         \"inception_ready_images/\",\n",
    "#         color_mode=\"grayscale\",\n",
    "#         target_size=(img_rows, img_cols),\n",
    "#         batch_size=1,\n",
    "#         class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Training Last Two Layers of Pretuned Model \n",
    "In this next section, we trained only the final layers of the pretuned model. This is for a number of reasons. First it is much fatser to only tune a few layers of a model than the entire model. Two, we believe that some of the underlying characteristics of images that are discovered in the InceptionV3 model will be very useful for us in classifying movie images. So, we do not want to remove those pretrained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### See how many layers we want to freeze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'input_1')\n",
      "(1, 'conv2d_1')\n",
      "(2, 'batch_normalization_1')\n",
      "(3, 'activation_1')\n",
      "(4, 'conv2d_2')\n",
      "(5, 'batch_normalization_2')\n",
      "(6, 'activation_2')\n",
      "(7, 'conv2d_3')\n",
      "(8, 'batch_normalization_3')\n",
      "(9, 'activation_3')\n",
      "(10, 'max_pooling2d_1')\n",
      "(11, 'conv2d_4')\n",
      "(12, 'batch_normalization_4')\n",
      "(13, 'activation_4')\n",
      "(14, 'conv2d_5')\n",
      "(15, 'batch_normalization_5')\n",
      "(16, 'activation_5')\n",
      "(17, 'max_pooling2d_2')\n",
      "(18, 'conv2d_9')\n",
      "(19, 'batch_normalization_9')\n",
      "(20, 'activation_9')\n",
      "(21, 'conv2d_7')\n",
      "(22, 'conv2d_10')\n",
      "(23, 'batch_normalization_7')\n",
      "(24, 'batch_normalization_10')\n",
      "(25, 'activation_7')\n",
      "(26, 'activation_10')\n",
      "(27, 'average_pooling2d_1')\n",
      "(28, 'conv2d_6')\n",
      "(29, 'conv2d_8')\n",
      "(30, 'conv2d_11')\n",
      "(31, 'conv2d_12')\n",
      "(32, 'batch_normalization_6')\n",
      "(33, 'batch_normalization_8')\n",
      "(34, 'batch_normalization_11')\n",
      "(35, 'batch_normalization_12')\n",
      "(36, 'activation_6')\n",
      "(37, 'activation_8')\n",
      "(38, 'activation_11')\n",
      "(39, 'activation_12')\n",
      "(40, 'mixed0')\n",
      "(41, 'conv2d_16')\n",
      "(42, 'batch_normalization_16')\n",
      "(43, 'activation_16')\n",
      "(44, 'conv2d_14')\n",
      "(45, 'conv2d_17')\n",
      "(46, 'batch_normalization_14')\n",
      "(47, 'batch_normalization_17')\n",
      "(48, 'activation_14')\n",
      "(49, 'activation_17')\n",
      "(50, 'average_pooling2d_2')\n",
      "(51, 'conv2d_13')\n",
      "(52, 'conv2d_15')\n",
      "(53, 'conv2d_18')\n",
      "(54, 'conv2d_19')\n",
      "(55, 'batch_normalization_13')\n",
      "(56, 'batch_normalization_15')\n",
      "(57, 'batch_normalization_18')\n",
      "(58, 'batch_normalization_19')\n",
      "(59, 'activation_13')\n",
      "(60, 'activation_15')\n",
      "(61, 'activation_18')\n",
      "(62, 'activation_19')\n",
      "(63, 'mixed1')\n",
      "(64, 'conv2d_23')\n",
      "(65, 'batch_normalization_23')\n",
      "(66, 'activation_23')\n",
      "(67, 'conv2d_21')\n",
      "(68, 'conv2d_24')\n",
      "(69, 'batch_normalization_21')\n",
      "(70, 'batch_normalization_24')\n",
      "(71, 'activation_21')\n",
      "(72, 'activation_24')\n",
      "(73, 'average_pooling2d_3')\n",
      "(74, 'conv2d_20')\n",
      "(75, 'conv2d_22')\n",
      "(76, 'conv2d_25')\n",
      "(77, 'conv2d_26')\n",
      "(78, 'batch_normalization_20')\n",
      "(79, 'batch_normalization_22')\n",
      "(80, 'batch_normalization_25')\n",
      "(81, 'batch_normalization_26')\n",
      "(82, 'activation_20')\n",
      "(83, 'activation_22')\n",
      "(84, 'activation_25')\n",
      "(85, 'activation_26')\n",
      "(86, 'mixed2')\n",
      "(87, 'conv2d_28')\n",
      "(88, 'batch_normalization_28')\n",
      "(89, 'activation_28')\n",
      "(90, 'conv2d_29')\n",
      "(91, 'batch_normalization_29')\n",
      "(92, 'activation_29')\n",
      "(93, 'conv2d_27')\n",
      "(94, 'conv2d_30')\n",
      "(95, 'batch_normalization_27')\n",
      "(96, 'batch_normalization_30')\n",
      "(97, 'activation_27')\n",
      "(98, 'activation_30')\n",
      "(99, 'max_pooling2d_3')\n",
      "(100, 'mixed3')\n",
      "(101, 'conv2d_35')\n",
      "(102, 'batch_normalization_35')\n",
      "(103, 'activation_35')\n",
      "(104, 'conv2d_36')\n",
      "(105, 'batch_normalization_36')\n",
      "(106, 'activation_36')\n",
      "(107, 'conv2d_32')\n",
      "(108, 'conv2d_37')\n",
      "(109, 'batch_normalization_32')\n",
      "(110, 'batch_normalization_37')\n",
      "(111, 'activation_32')\n",
      "(112, 'activation_37')\n",
      "(113, 'conv2d_33')\n",
      "(114, 'conv2d_38')\n",
      "(115, 'batch_normalization_33')\n",
      "(116, 'batch_normalization_38')\n",
      "(117, 'activation_33')\n",
      "(118, 'activation_38')\n",
      "(119, 'average_pooling2d_4')\n",
      "(120, 'conv2d_31')\n",
      "(121, 'conv2d_34')\n",
      "(122, 'conv2d_39')\n",
      "(123, 'conv2d_40')\n",
      "(124, 'batch_normalization_31')\n",
      "(125, 'batch_normalization_34')\n",
      "(126, 'batch_normalization_39')\n",
      "(127, 'batch_normalization_40')\n",
      "(128, 'activation_31')\n",
      "(129, 'activation_34')\n",
      "(130, 'activation_39')\n",
      "(131, 'activation_40')\n",
      "(132, 'mixed4')\n",
      "(133, 'conv2d_45')\n",
      "(134, 'batch_normalization_45')\n",
      "(135, 'activation_45')\n",
      "(136, 'conv2d_46')\n",
      "(137, 'batch_normalization_46')\n",
      "(138, 'activation_46')\n",
      "(139, 'conv2d_42')\n",
      "(140, 'conv2d_47')\n",
      "(141, 'batch_normalization_42')\n",
      "(142, 'batch_normalization_47')\n",
      "(143, 'activation_42')\n",
      "(144, 'activation_47')\n",
      "(145, 'conv2d_43')\n",
      "(146, 'conv2d_48')\n",
      "(147, 'batch_normalization_43')\n",
      "(148, 'batch_normalization_48')\n",
      "(149, 'activation_43')\n",
      "(150, 'activation_48')\n",
      "(151, 'average_pooling2d_5')\n",
      "(152, 'conv2d_41')\n",
      "(153, 'conv2d_44')\n",
      "(154, 'conv2d_49')\n",
      "(155, 'conv2d_50')\n",
      "(156, 'batch_normalization_41')\n",
      "(157, 'batch_normalization_44')\n",
      "(158, 'batch_normalization_49')\n",
      "(159, 'batch_normalization_50')\n",
      "(160, 'activation_41')\n",
      "(161, 'activation_44')\n",
      "(162, 'activation_49')\n",
      "(163, 'activation_50')\n",
      "(164, 'mixed5')\n",
      "(165, 'conv2d_55')\n",
      "(166, 'batch_normalization_55')\n",
      "(167, 'activation_55')\n",
      "(168, 'conv2d_56')\n",
      "(169, 'batch_normalization_56')\n",
      "(170, 'activation_56')\n",
      "(171, 'conv2d_52')\n",
      "(172, 'conv2d_57')\n",
      "(173, 'batch_normalization_52')\n",
      "(174, 'batch_normalization_57')\n",
      "(175, 'activation_52')\n",
      "(176, 'activation_57')\n",
      "(177, 'conv2d_53')\n",
      "(178, 'conv2d_58')\n",
      "(179, 'batch_normalization_53')\n",
      "(180, 'batch_normalization_58')\n",
      "(181, 'activation_53')\n",
      "(182, 'activation_58')\n",
      "(183, 'average_pooling2d_6')\n",
      "(184, 'conv2d_51')\n",
      "(185, 'conv2d_54')\n",
      "(186, 'conv2d_59')\n",
      "(187, 'conv2d_60')\n",
      "(188, 'batch_normalization_51')\n",
      "(189, 'batch_normalization_54')\n",
      "(190, 'batch_normalization_59')\n",
      "(191, 'batch_normalization_60')\n",
      "(192, 'activation_51')\n",
      "(193, 'activation_54')\n",
      "(194, 'activation_59')\n",
      "(195, 'activation_60')\n",
      "(196, 'mixed6')\n",
      "(197, 'conv2d_65')\n",
      "(198, 'batch_normalization_65')\n",
      "(199, 'activation_65')\n",
      "(200, 'conv2d_66')\n",
      "(201, 'batch_normalization_66')\n",
      "(202, 'activation_66')\n",
      "(203, 'conv2d_62')\n",
      "(204, 'conv2d_67')\n",
      "(205, 'batch_normalization_62')\n",
      "(206, 'batch_normalization_67')\n",
      "(207, 'activation_62')\n",
      "(208, 'activation_67')\n",
      "(209, 'conv2d_63')\n",
      "(210, 'conv2d_68')\n",
      "(211, 'batch_normalization_63')\n",
      "(212, 'batch_normalization_68')\n",
      "(213, 'activation_63')\n",
      "(214, 'activation_68')\n",
      "(215, 'average_pooling2d_7')\n",
      "(216, 'conv2d_61')\n",
      "(217, 'conv2d_64')\n",
      "(218, 'conv2d_69')\n",
      "(219, 'conv2d_70')\n",
      "(220, 'batch_normalization_61')\n",
      "(221, 'batch_normalization_64')\n",
      "(222, 'batch_normalization_69')\n",
      "(223, 'batch_normalization_70')\n",
      "(224, 'activation_61')\n",
      "(225, 'activation_64')\n",
      "(226, 'activation_69')\n",
      "(227, 'activation_70')\n",
      "(228, 'mixed7')\n",
      "(229, 'conv2d_73')\n",
      "(230, 'batch_normalization_73')\n",
      "(231, 'activation_73')\n",
      "(232, 'conv2d_74')\n",
      "(233, 'batch_normalization_74')\n",
      "(234, 'activation_74')\n",
      "(235, 'conv2d_71')\n",
      "(236, 'conv2d_75')\n",
      "(237, 'batch_normalization_71')\n",
      "(238, 'batch_normalization_75')\n",
      "(239, 'activation_71')\n",
      "(240, 'activation_75')\n",
      "(241, 'conv2d_72')\n",
      "(242, 'conv2d_76')\n",
      "(243, 'batch_normalization_72')\n",
      "(244, 'batch_normalization_76')\n",
      "(245, 'activation_72')\n",
      "(246, 'activation_76')\n",
      "(247, 'max_pooling2d_4')\n",
      "(248, 'mixed8')\n",
      "(249, 'conv2d_81')\n",
      "(250, 'batch_normalization_81')\n",
      "(251, 'activation_81')\n",
      "(252, 'conv2d_78')\n",
      "(253, 'conv2d_82')\n",
      "(254, 'batch_normalization_78')\n",
      "(255, 'batch_normalization_82')\n",
      "(256, 'activation_78')\n",
      "(257, 'activation_82')\n",
      "(258, 'conv2d_79')\n",
      "(259, 'conv2d_80')\n",
      "(260, 'conv2d_83')\n",
      "(261, 'conv2d_84')\n",
      "(262, 'average_pooling2d_8')\n",
      "(263, 'conv2d_77')\n",
      "(264, 'batch_normalization_79')\n",
      "(265, 'batch_normalization_80')\n",
      "(266, 'batch_normalization_83')\n",
      "(267, 'batch_normalization_84')\n",
      "(268, 'conv2d_85')\n",
      "(269, 'batch_normalization_77')\n",
      "(270, 'activation_79')\n",
      "(271, 'activation_80')\n",
      "(272, 'activation_83')\n",
      "(273, 'activation_84')\n",
      "(274, 'batch_normalization_85')\n",
      "(275, 'activation_77')\n",
      "(276, 'mixed9_0')\n",
      "(277, 'concatenate_1')\n",
      "(278, 'activation_85')\n",
      "(279, 'mixed9')\n",
      "(280, 'conv2d_90')\n",
      "(281, 'batch_normalization_90')\n",
      "(282, 'activation_90')\n",
      "(283, 'conv2d_87')\n",
      "(284, 'conv2d_91')\n",
      "(285, 'batch_normalization_87')\n",
      "(286, 'batch_normalization_91')\n",
      "(287, 'activation_87')\n",
      "(288, 'activation_91')\n",
      "(289, 'conv2d_88')\n",
      "(290, 'conv2d_89')\n",
      "(291, 'conv2d_92')\n",
      "(292, 'conv2d_93')\n",
      "(293, 'average_pooling2d_9')\n",
      "(294, 'conv2d_86')\n",
      "(295, 'batch_normalization_88')\n",
      "(296, 'batch_normalization_89')\n",
      "(297, 'batch_normalization_92')\n",
      "(298, 'batch_normalization_93')\n",
      "(299, 'conv2d_94')\n",
      "(300, 'batch_normalization_86')\n",
      "(301, 'activation_88')\n",
      "(302, 'activation_89')\n",
      "(303, 'activation_92')\n",
      "(304, 'activation_93')\n",
      "(305, 'batch_normalization_94')\n",
      "(306, 'activation_86')\n",
      "(307, 'mixed9_1')\n",
      "(308, 'concatenate_2')\n",
      "(309, 'activation_94')\n",
      "(310, 'mixed10')\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In total we have 310 layers prebuilt, we'll freeze everything but the last 2 in order to do our finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:308]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[308:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "### Lr is the learning rate, this is set currently to be relatively low \n",
    "### however, if we wanted to learn more quickly on each update we would increase this \n",
    "### THIS IS SOMETHING THAT WE CAN TEST \n",
    "## The other thing that we can check out is momentum , momentum is how much \n",
    "### the model continues to learn in the same direction. This is another model that we could check to see how \n",
    "## important it is via cross validation potentially. \n",
    "## Explanation is here http://sebastianruder.com/optimizing-gradient-descent/index.html#momentum \n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "#model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 25s - loss: 0.4891 - acc: 0.8118 - val_loss: 0.4768 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 23s - loss: 0.5331 - acc: 0.7882 - val_loss: 0.4758 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 22s - loss: 0.4464 - acc: 0.8471 - val_loss: 0.4725 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 16s - loss: 0.5801 - acc: 0.7882 - val_loss: 0.4641 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 17s - loss: 0.5312 - acc: 0.8118 - val_loss: 0.4561 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 16s - loss: 0.3977 - acc: 0.8353 - val_loss: 0.4473 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 16s - loss: 0.5439 - acc: 0.8000 - val_loss: 0.4448 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 17s - loss: 0.5770 - acc: 0.7882 - val_loss: 0.4462 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 17s - loss: 0.4488 - acc: 0.8235 - val_loss: 0.4465 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 17s - loss: 0.6163 - acc: 0.7765 - val_loss: 0.4484 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 18s - loss: 0.5006 - acc: 0.8235 - val_loss: 0.4519 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 18s - loss: 0.4475 - acc: 0.8118 - val_loss: 0.4515 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 16s - loss: 0.5584 - acc: 0.8000 - val_loss: 0.4487 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 20s - loss: 0.4960 - acc: 0.8235 - val_loss: 0.4490 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 18s - loss: 0.5163 - acc: 0.7765 - val_loss: 0.4482 - val_acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "history_prefit = model.fit_generator(datagen.flow(x_train[0:20], y_train[0:20], batch_size = 1), steps_per_epoch = 5, epochs = 15,validation_data=(x_test[0:20], y_test[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.44308662414550781)\n",
      "('Test accuracy:', 0.84117650985717773)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test[0:20], y_test[0:20], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12d48a690>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGDCAYAAAAs+rl+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d45e4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history_prefit.history['acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title(\"Accuracy as a function of epochs\")\n",
    "#plt.subtitle(\"Note how the number of epochs effects our prefit model LESS than our other model\")\n",
    "plt.ylim([.5,.9])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters in the Final Two Layers: \n",
    "Let's check out some other parameters to tune to see how they affect our neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Discussion of the results, how much improvement you gained with fine tuning, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Discussion of at least one additional exploratory idea you pursued \n",
    "In this section, we might want to add in other features/other ideas etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
