{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 4: Deep learning, due Wednesday, April 26, 2017\n",
    "\n",
    "For this milestone you will (finally) use deep learning to predict movie genres. You will train one small network from scratch on the posters only, and compare this one to a pre-trained network that you fine tune. [Here](https://keras.io/getting-started/faq/#how-can-i-use-pre-trained-models-in-keras) is a description of how to use pretrained models in Keras.\n",
    "\n",
    "You can try different architectures, initializations, parameter settings, optimization methods, etc. Be adventurous and explore deep learning! It can be fun to combine the features learned by the deep learning model with a SVM, or incorporate meta data into your deep learning model. \n",
    "\n",
    "**Note:** Be mindful of the longer training times for deep models. Not only for training time, but also for the parameter tuning efforts. You need time to develop a feel for the different parameters and which settings work, which normalization you want to use, which model architecture you choose, etc. \n",
    "\n",
    "It is great that we have GPUs via AWS to speed up the actual computation time, but you need to be mindful of your AWS credits. The GPU instances are not cheap and can accumulate costs rather quickly. Think about your model first and do some quick dry runs with a larger learning rate or large batch size on your local machine. \n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. \n",
    "- Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. \n",
    "- Discussion of the results, how much improvement you gained with fine tuning, etc. \n",
    "- Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# for image manipulation. Easier to do \n",
    "# here than with Keras, as per\n",
    "# https://piazza.com/class/ivlbdd3nigy3um?cid=818\n",
    "#!sudo pip install Image\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step One: Extracting Movies From URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"train_full.csv\")\n",
    "# train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "# print \"Train shape:\", train.shape\n",
    "# train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_thinned shape: (540, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10402</th>\n",
       "      <th>10749</th>\n",
       "      <th>10751</th>\n",
       "      <th>10752</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>lead actors</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[u'Alec Baldwin', u'Miles Bakshi', u'Jimmy Kim...</td>\n",
       "      <td>295693</td>\n",
       "      <td>A story about how a new baby's arrival impacts...</td>\n",
       "      <td>305.881041</td>\n",
       "      <td>/unPB1iyEeTBcKiLg8W083rlViFH.jpg</td>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>The Boss Baby</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10402  10749  10751  10752  12  14  16  18  27  28    ...      \\\n",
       "0      0      0      1      0   0   0   1   0   0   0    ...       \n",
       "\n",
       "                                         lead actors  movie_id  \\\n",
       "0  [u'Alec Baldwin', u'Miles Bakshi', u'Jimmy Kim...    295693   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  A story about how a new baby's arrival impacts...  305.881041   \n",
       "\n",
       "                        poster_path  release_date          title  video  \\\n",
       "0  /unPB1iyEeTBcKiLg8W083rlViFH.jpg    2017-03-23  The Boss Baby  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          5.7        510  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_thinned = pd.read_csv(\"train.csv\")\n",
    "train_thinned.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "print \"train_thinned shape:\", train_thinned.shape\n",
    "train_thinned.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Important. \n",
    "\n",
    "The line below aliases the DF that we want to work with as `curr_df`. When we decide later on to use the full training set instead of just `train_thinned`, all we need to do is set it in the cell below and re-run the code. This will prevent us from having to find/replace all instances of the past dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "curr_df = train_thinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Helper that downloads web images \n",
    "## Takes in the poster path and the id of the movie \n",
    "## Saves the movie as a jpg as the unique id of the movie \n",
    "## In the images folder.\n",
    "def download_web_image(poster_path, movie_id):\n",
    "    # given that we're going to resize our images to be 32x32\n",
    "    # or something else really small, let's download really small images \n",
    "    # to start\n",
    "    base_url = \"https://image.tmdb.org/t/p/w92/\" \n",
    "    \n",
    "    request = urllib2.Request(base_url + poster_path)\n",
    "    img = urllib2.urlopen(request).read()\n",
    "    image_name= \"images/\" + str(movie_id) + \".jpg\"\n",
    "    \n",
    "    with open(image_name, 'w') as f: \n",
    "        f.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you actually want to download posters, you'll need to turn the `1` above into a `0`. This code doesn't run by default in the notebook so that you don't accidentally download hundreds of images.\n"
     ]
    }
   ],
   "source": [
    "### iterate through all of the images in the thinned dataset, saving locally \n",
    "if 1:\n",
    "    print \"If you actually want to download posters, you'll need to turn the `1` above into a `0`. This code doesn't run by default in the notebook so that you don't accidentally download hundreds of images.\"\n",
    "else:\n",
    "    for index, row in curr_df.iterrows():\n",
    "        movie_id = row[\"movie_id\"]\n",
    "        poster_path = row[\"poster_path\"] \n",
    "#         download_web_image(poster_path, movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# convert each normal poster to a 32x32 grayscale poster\n",
    "for img_name in os.listdir(\"images/\"):\n",
    "    ## This line added to avoid hidden files on mac (Stephen)\n",
    "    if not img_name.startswith('.'):\n",
    "        # read in an image and convert to greyscale\n",
    "        im = Image.open(\"images/\" + img_name).convert(\"L\")\n",
    "        out = im.resize((img_rows, img_cols))\n",
    "        out.save(\"nn_ready_images/\" + img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Building a CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of labels in our output\n",
    "n_labels = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now we need training and testing data. in the current state,\n",
    "# we have a bunch of greyscale images named by their movie ids.\n",
    "# to get the data, we can first just split all the movie ids (X) in the\n",
    "# dataframe intro train and test sets, and then grab their multilabel\n",
    "# matrices (y)\n",
    "m_ids = curr_df.movie_id.values\n",
    "\n",
    "# shuffle the ids to get a random sample\n",
    "np.random.shuffle(m_ids)\n",
    "\n",
    "import math\n",
    "train_size = int(math.floor(.7 * len(m_ids)))\n",
    "\n",
    "# get the movie_ids (each of which has an image in \"nn_images_ready/\"\n",
    "# which is ready to be put through the neural net\n",
    "train_ids = m_ids[:train_size]\n",
    "test_ids = m_ids[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (378, 17)\n",
      "y_test shape: (162, 17)\n"
     ]
    }
   ],
   "source": [
    "# these are the column names of the multilabel matrix\n",
    "label_names = curr_df.columns[:n_labels]\n",
    "\n",
    "y_train = np.array([curr_df[curr_df.movie_id == movie_id][label_names].values[0] for movie_id in train_ids])\n",
    "y_test  = np.array([curr_df[curr_df.movie_id == movie_id][label_names].values[0] for movie_id in test_ids])\n",
    "\n",
    "# should be (num_samples, num_labels)\n",
    "print \"y_train shape:\", y_train.shape\n",
    "print \"y_test shape:\", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# smaller batch size means noisier gradient, but more updates per epoch\n",
    "batch_size = 512\n",
    "\n",
    "# number of iterations over the complete training data\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load image matrices into memory\n",
    "x_train = np.array([np.asarray(Image.open(\"nn_ready_images/\" + str(m_id) + \".jpg\")) for m_id in train_ids])\n",
    "x_test =  np.array([np.asarray(Image.open(\"nn_ready_images/\" + str(m_id) + \".jpg\")) for m_id in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (378, 32, 32)\n",
      "x_test shape: (162, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# output should be (num_images, img_height, img_width)\n",
    "print \"x_train shape:\", x_train.shape\n",
    "print \"x_test shape:\", x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (378, 32, 32, 1)\n",
      "378 train samples\n",
      "162 test samples\n"
     ]
    }
   ],
   "source": [
    "# code borrowed from Keras_CNN lab\n",
    "\n",
    "# now we need to reshape x_train and x_test so that they work with CNNs\n",
    "# Following the example in \"labs/Keras_CNN.ipynb\", this needs to be an array \n",
    "# of images with shape determined by the backend, including the depth dimension,\n",
    "# which is 1 for greyscale\n",
    "\n",
    "# x_train is of shape n_samples x 32 x 32\n",
    "# for a CNN we want to keep the image shape\n",
    "# need to explicitly tell keras that it is a gray value image\n",
    "# so each image is 32x32x1 not 32x32x3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# normalize image values to [0,1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print \"x_train shape:\", x_train.shape\n",
    "print x_train.shape[0], \"train samples\"\n",
    "print x_test.shape[0], \"test samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                1105      \n",
      "=================================================================\n",
      "Total params: 41,105.0\n",
      "Trainable params: 41,105.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model = Sequential()\n",
    "\n",
    "# define the input layer to the CNN\n",
    "# input shape is a tuple of the # rows, # cols, and # channels (1 for grayscale)\n",
    "# the first parameter to Conv2D is the number of filters we want to convolve\n",
    "# over the input images\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add another convolution layer\n",
    "# we could double the number of filters as max pool made the \n",
    "# feature maps much smaller, but we're not doing this to improve runtime\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# ================\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# create a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# ================\n",
    "\n",
    "# flatten for fully connected classification layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# note that the 10 is the number of classes we have\n",
    "# the classes are mutually exclusive so softmax is a good choice\n",
    "# --- fully connected layer ---\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# recommended by: https://github.com/fchollet/keras/issues/761\n",
    "# uses a sigmoid activation rather than softmax, which apparently\n",
    "# gives us a label vector back\n",
    "model.add(Dense(n_labels, activation='sigmoid'))\n",
    "\n",
    "# prints out a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "Let's use a large learning rate (0.1) while we're working locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the setup is our basic categorical crossentropy with stochastic gradient decent\n",
    "# we also specify that we want to evaluate our model in terms of accuracy\n",
    "sgd = SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# TODO: why are we using binary crossentropy?\n",
    "# I'm not sure, but it works much better than\n",
    "# categorical crossentropy.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378 samples, validate on 162 samples\n",
      "Epoch 1/15\n",
      "378/378 [==============================] - 0s - loss: 0.7000 - acc: 0.4202 - val_loss: 0.6933 - val_acc: 0.4601\n",
      "Epoch 2/15\n",
      "378/378 [==============================] - 0s - loss: 0.6950 - acc: 0.4402 - val_loss: 0.6844 - val_acc: 0.5225\n",
      "Epoch 3/15\n",
      "378/378 [==============================] - 0s - loss: 0.6861 - acc: 0.4956 - val_loss: 0.6728 - val_acc: 0.6594\n",
      "Epoch 4/15\n",
      "378/378 [==============================] - 0s - loss: 0.6744 - acc: 0.6394 - val_loss: 0.6608 - val_acc: 0.7033\n",
      "Epoch 5/15\n",
      "378/378 [==============================] - 0s - loss: 0.6624 - acc: 0.6891 - val_loss: 0.6462 - val_acc: 0.7244\n",
      "Epoch 6/15\n",
      "378/378 [==============================] - 0s - loss: 0.6477 - acc: 0.7132 - val_loss: 0.6265 - val_acc: 0.7462\n",
      "Epoch 7/15\n",
      "378/378 [==============================] - 0s - loss: 0.6281 - acc: 0.7356 - val_loss: 0.5988 - val_acc: 0.8017\n",
      "Epoch 8/15\n",
      "378/378 [==============================] - 0s - loss: 0.6008 - acc: 0.7975 - val_loss: 0.5596 - val_acc: 0.8297\n",
      "Epoch 9/15\n",
      "378/378 [==============================] - 0s - loss: 0.5626 - acc: 0.8254 - val_loss: 0.5089 - val_acc: 0.8293\n",
      "Epoch 10/15\n",
      "378/378 [==============================] - 0s - loss: 0.5140 - acc: 0.8265 - val_loss: 0.4599 - val_acc: 0.8293\n",
      "Epoch 11/15\n",
      "378/378 [==============================] - 0s - loss: 0.4691 - acc: 0.8265 - val_loss: 0.4419 - val_acc: 0.8293\n",
      "Epoch 12/15\n",
      "378/378 [==============================] - 0s - loss: 0.4558 - acc: 0.8265 - val_loss: 0.4534 - val_acc: 0.8293\n",
      "Epoch 13/15\n",
      "378/378 [==============================] - 0s - loss: 0.4660 - acc: 0.8265 - val_loss: 0.4485 - val_acc: 0.8293\n",
      "Epoch 14/15\n",
      "378/378 [==============================] - 0s - loss: 0.4493 - acc: 0.8265 - val_loss: 0.4447 - val_acc: 0.8177\n",
      "Epoch 15/15\n",
      "378/378 [==============================] - 0s - loss: 0.4295 - acc: 0.8193 - val_loss: 0.4618 - val_acc: 0.7988\n"
     ]
    }
   ],
   "source": [
    "# this is now the actual training\n",
    "# in addition to the training data we provide validation data\n",
    "# this data is used to calculate the performance of the model over all the epochs\n",
    "# this is useful to determine when training should stop\n",
    "# in our case we just use it to monitor the evolution of the model over the training epochs\n",
    "# if we use the validation data to determine when to stop the training or which model to save, we \n",
    "# should not use the test data, but a separate validation set. \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.46178770948339393)\n",
      "('Test accuracy:', 0.79883808118325694)\n"
     ]
    }
   ],
   "source": [
    "# once training is complete, let's see how well we have done\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f85dcd37890>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGJCAYAAACTqKqrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85dcd76110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title(\"Accuracy as a function of epochs\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ToDos for #1\n",
    "1. Binary Categorization?\n",
    "2. Accuracy?\n",
    "3. Last layer for doing multilabel (is sigmoid correct?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Fine tuning a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our baseline? \n",
    "To begin it's important to know what does \"good\" even mean in a model? In order to do this, we needed a baseline accuracy that we thought would be a good benchmark to beat. For this multilabel classification problem, we face an extremely sparse matrix. Most movies are only in a few of the many categorie. As "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert Images to Format for InceptionV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Because inception takes in a 299 x 299 RGB image, we need to download them as such \n",
    "img_rows, img_cols = 299, 299\n",
    "\n",
    "# convert each normal poster to a 299x299 poster\n",
    "for img_name in os.listdir(\"images/\"):\n",
    "    if not img_name.startswith('.'):\n",
    "        # read in an image, do not convert to greyscale \n",
    "        im = Image.open(\"images/\" + img_name)\n",
    "        out = im.resize((img_rows, img_cols))\n",
    "        ## save to the inception images folder \n",
    "        out.save(\"inception_ready_images/\" + img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load image matrices into memory\n",
    "x_train = np.array([np.asarray(Image.open(\"inception_ready_images/\" + str(m_id) + \".jpg\")) for m_id in train_ids])\n",
    "x_test =  np.array([np.asarray(Image.open(\"inception_ready_images/\" + str(m_id) + \".jpg\")) for m_id in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 299, 299, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Our data is of the format that we can use for inception \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 299, 299, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## convert data into tuple of training data\n",
    "## model.fit_generator takes a tuple \n",
    "training = (x_train, y_train)\n",
    "\n",
    "test = (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights= 'imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(n_labels, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "# model.fit_generator(x_train, y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f85a6e4a910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85a6e4a510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85a6e4a8d0>,\n",
       " <keras.layers.core.Activation at 0x7f85a6e4abd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85dcddded0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85a4035a10>,\n",
       " <keras.layers.core.Activation at 0x7f85dd486f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85dd453490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85dd446ad0>,\n",
       " <keras.layers.core.Activation at 0x7f85dd418c10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f85dd3d3b90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85dd3e21d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85dd392f50>,\n",
       " <keras.layers.core.Activation at 0x7f857697a2d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857698cb90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857691b850>,\n",
       " <keras.layers.core.Activation at 0x7f85768e1950>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f857689ded0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857674d6d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857673ebd0>,\n",
       " <keras.layers.core.Activation at 0x7f8576692250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857682bed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85766cfc90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857682b550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857668df50>,\n",
       " <keras.layers.core.Activation at 0x7f8576795f50>,\n",
       " <keras.layers.core.Activation at 0x7f8576622a50>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f85765babd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857689d210>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85768016d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85765e0f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576573450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857685ae90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85767bd190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85765e03d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85765389d0>,\n",
       " <keras.layers.core.Activation at 0x7f8576885f50>,\n",
       " <keras.layers.core.Activation at 0x7f8576713290>,\n",
       " <keras.layers.core.Activation at 0x7f85765cced0>,\n",
       " <keras.layers.core.Activation at 0x7f85764e1ad0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8576505950>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857636bb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576329050>,\n",
       " <keras.layers.core.Activation at 0x7f8576295990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576486f90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85762b65d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576416110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85762aaa50>,\n",
       " <keras.layers.core.Activation at 0x7f85763d9990>,\n",
       " <keras.layers.core.Activation at 0x7f8576226550>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f85761618d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576499b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85763ab450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857623cad0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85761ce350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85764c9410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576399310>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857624e750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857618dc10>,\n",
       " <keras.layers.core.Activation at 0x7f857646ebd0>,\n",
       " <keras.layers.core.Activation at 0x7f857637fe10>,\n",
       " <keras.layers.core.Activation at 0x7f8576191850>,\n",
       " <keras.layers.core.Activation at 0x7f857613ad90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85760f3d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575f87b10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575f16790>,\n",
       " <keras.layers.core.Activation at 0x7f8575ede890>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85760c9c10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575eaa910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576070090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575e97090>,\n",
       " <keras.layers.core.Activation at 0x7f857604f150>,\n",
       " <keras.layers.core.Activation at 0x7f8575e6ea10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8575d69f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85760dfb90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576003610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575e29910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575dacad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85760a2650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575ff6a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575e18d90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575d7cb90>,\n",
       " <keras.layers.core.Activation at 0x7f85760c9e10>,\n",
       " <keras.layers.core.Activation at 0x7f8575f70590>,\n",
       " <keras.layers.core.Activation at 0x7f8575d95890>,\n",
       " <keras.layers.core.Activation at 0x7f8575d28550>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8575d3dc90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575ccdb50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575c5a7d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575c208d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575bf1390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575bde0d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575bbaa50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575d3d7d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575b75950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575cf9f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575b63dd0>,\n",
       " <keras.layers.core.Activation at 0x7f8575cb65d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575adf8d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f8575ab3f90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8575af6b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85758bb990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575901a90>,\n",
       " <keras.layers.core.Activation at 0x7f8575828910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857583ee90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857584d110>,\n",
       " <keras.layers.core.Activation at 0x7f85757b94d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575a15690>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85757cda50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575a87b10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857575d6d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575a02610>,\n",
       " <keras.layers.core.Activation at 0x7f85757247d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575996b90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85756f1e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85759a6810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85756dc110>,\n",
       " <keras.layers.core.Activation at 0x7f857596c910>,\n",
       " <keras.layers.core.Activation at 0x7f85756b7390>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f85755f2d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575a9c710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857593a3d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575672850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575600410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575ac7bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575928110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575662cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85755c8310>,\n",
       " <keras.layers.core.Activation at 0x7f8575a6fa50>,\n",
       " <keras.layers.core.Activation at 0x7f8575894d50>,\n",
       " <keras.layers.core.Activation at 0x7f85755de7d0>,\n",
       " <keras.layers.core.Activation at 0x7f857556f490>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8575583bd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85752faf10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857534ba50>,\n",
       " <keras.layers.core.Activation at 0x7f8575310b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85752cf990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575260610>,\n",
       " <keras.layers.core.Activation at 0x7f8575223710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575497ad0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85751f2dd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85754a7750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85751df050>,\n",
       " <keras.layers.core.Activation at 0x7f857546f850>,\n",
       " <keras.layers.core.Activation at 0x7f85751b72d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857543f8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575171790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857542b090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575163c10>,\n",
       " <keras.layers.core.Activation at 0x7f85754019d0>,\n",
       " <keras.layers.core.Activation at 0x7f85750dd710>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8575086ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575511850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85753bb8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85750f4c90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575086510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575541e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85753acd50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575102910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575046dd0>,\n",
       " <keras.layers.core.Activation at 0x7f8575503550>,\n",
       " <keras.layers.core.Activation at 0x7f8575328850>,\n",
       " <keras.layers.core.Activation at 0x7f85750c8a10>,\n",
       " <keras.layers.core.Activation at 0x7f8574feef90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8574fa7910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574d51f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574d513d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574d3ced0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574d26bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574ce0110>,\n",
       " <keras.layers.core.Activation at 0x7f8574cbc1d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574f3ce10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574c71690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574f29090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574c63b10>,\n",
       " <keras.layers.core.Activation at 0x7f8574f00310>,\n",
       " <keras.layers.core.Activation at 0x7f8574bdc610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574eba7d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574bf3b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574eaac50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574c01810>,\n",
       " <keras.layers.core.Activation at 0x7f8574e28750>,\n",
       " <keras.layers.core.Activation at 0x7f8574bc6910>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8574a9a990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574f94d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574e40cd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574b173d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574add4d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574f56810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574e4f950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574b83110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574a5b450>,\n",
       " <keras.layers.core.Activation at 0x7f8574f82fd0>,\n",
       " <keras.layers.core.Activation at 0x7f8574d93a50>,\n",
       " <keras.layers.core.Activation at 0x7f8574af0d50>,\n",
       " <keras.layers.core.Activation at 0x7f8574a84a10>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8574a29810>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85747e2990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574829a90>,\n",
       " <keras.layers.core.Activation at 0x7f85747d0910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574765e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574773110>,\n",
       " <keras.layers.core.Activation at 0x7f85746de4d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85749b9690>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85746f4a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85749abb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85747056d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574928610>,\n",
       " <keras.layers.core.Activation at 0x7f85746c97d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857493cb90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574619e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574949810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574685110>,\n",
       " <keras.layers.core.Activation at 0x7f8574910910>,\n",
       " <keras.layers.core.Activation at 0x7f85745e0390>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8574519d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575583710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85748613d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574598850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574528410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85749ec710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85748ce110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574607cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85744ed310>,\n",
       " <keras.layers.core.Activation at 0x7f8574995950>,\n",
       " <keras.layers.core.Activation at 0x7f8574838d50>,\n",
       " <keras.layers.core.Activation at 0x7f85745837d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574499490>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85744acbd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574361890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85743ce150>,\n",
       " <keras.layers.core.Activation at 0x7f8574325990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85742e1890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85742d2d10>,\n",
       " <keras.layers.core.Activation at 0x7f85742cd810>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85744ac710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574222ed0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857446bd10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574273a10>,\n",
       " <keras.layers.core.Activation at 0x7f8574428510>,\n",
       " <keras.layers.core.Activation at 0x7f8574236b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857443ea90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85741f3950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857444f710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85742063d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574392810>,\n",
       " <keras.layers.core.Activation at 0x7f85741c86d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f857411cd90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85741891d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573f41510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573effb10>,\n",
       " <keras.layers.core.Activation at 0x7f8573ebc350>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85740ab910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573ecff50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857409a090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573ecf410>,\n",
       " <keras.layers.core.Activation at 0x7f8574071a10>,\n",
       " <keras.layers.core.Activation at 0x7f8573e39f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857402b910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573f69f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573e25c10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573d746d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8573cf6710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857414aa90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857401ad90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573fab950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573de1150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573d66b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573cb7f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85740e2850>,\n",
       " <keras.layers.core.Activation at 0x7f8573f95890>,\n",
       " <keras.layers.core.Activation at 0x7f8573f2c450>,\n",
       " <keras.layers.core.Activation at 0x7f8573dbe210>,\n",
       " <keras.layers.core.Activation at 0x7f8573ce1650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573ccdf10>,\n",
       " <keras.layers.core.Activation at 0x7f8574109150>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573f419d0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573cf6bd0>,\n",
       " <keras.layers.core.Activation at 0x7f8573c73650>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573c48ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85739e8810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85739930d0>,\n",
       " <keras.layers.core.Activation at 0x7f85739ba8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573b9cc50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857398ff90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573baa8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573951990>,\n",
       " <keras.layers.core.Activation at 0x7f8573b6d9d0>,\n",
       " <keras.layers.core.Activation at 0x7f857394f490>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573b2de90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573b05b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85738e4a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573887e50>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f857379ba10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573c87a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573b2d350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573abd090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85738f6690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85738740d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85737604d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573bdd350>,\n",
       " <keras.layers.core.Activation at 0x7f8573a97e50>,\n",
       " <keras.layers.core.Activation at 0x7f8573a18150>,\n",
       " <keras.layers.core.Activation at 0x7f85738b9790>,\n",
       " <keras.layers.core.Activation at 0x7f857384f350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85737ca410>,\n",
       " <keras.layers.core.Activation at 0x7f8573c056d0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573a4f610>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573807810>,\n",
       " <keras.layers.core.Activation at 0x7f85737199d0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573719350>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## http://stackoverflow.com/questions/40574386/keras-model-fit-generator \n",
    "## This, in theory should generate the data in a way that we want. \n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 3s - loss: 2.3942 - acc: 0.8118 - val_loss: 2.7922 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 2s - loss: 2.9340 - acc: 0.8176 - val_loss: 2.7924 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 2s - loss: 2.1786 - acc: 0.8647 - val_loss: 2.8194 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8573312050>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check out the validation set on this \n",
    "### SHOULD BE CHANGED TO VALIDATION SET \n",
    "model.fit_generator(datagen.flow(x_train[0:20], y_train[0:20], batch_size = 1), steps_per_epoch = 10, epochs = 3, validation_data=(x_test[0:20], y_test[:20]))\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "# model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "#                     steps_per_epoch=len(X_train) / 32, epochs=epochs)\n",
    "\n",
    "# ## Might need to use this generator \n",
    "\n",
    "# train_datagen = ImageDataGenerator()\n",
    "\n",
    "# train_datagen.fit\n",
    "\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         \"inception_ready_images/\",\n",
    "#         color_mode=\"grayscale\",\n",
    "#         target_size=(img_rows, img_cols),\n",
    "#         batch_size=1,\n",
    "#         class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "## Training Last Two Layers of Pretuned Model \n",
    "In this next section, we trained only the final layers of the pretuned model. This is for a number of reasons. First it is much fatser to only tune a few layers of a model than the entire model. Two, we believe that some of the underlying characteristics of images that are discovered in the InceptionV3 model will be very useful for us in classifying movie images. So, we do not want to remove those pretrained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### See how many layers we want to freeze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'input_1')\n",
      "(1, 'conv2d_4')\n",
      "(2, 'batch_normalization_1')\n",
      "(3, 'activation_1')\n",
      "(4, 'conv2d_5')\n",
      "(5, 'batch_normalization_2')\n",
      "(6, 'activation_2')\n",
      "(7, 'conv2d_6')\n",
      "(8, 'batch_normalization_3')\n",
      "(9, 'activation_3')\n",
      "(10, 'max_pooling2d_4')\n",
      "(11, 'conv2d_7')\n",
      "(12, 'batch_normalization_4')\n",
      "(13, 'activation_4')\n",
      "(14, 'conv2d_8')\n",
      "(15, 'batch_normalization_5')\n",
      "(16, 'activation_5')\n",
      "(17, 'max_pooling2d_5')\n",
      "(18, 'conv2d_12')\n",
      "(19, 'batch_normalization_9')\n",
      "(20, 'activation_9')\n",
      "(21, 'conv2d_10')\n",
      "(22, 'conv2d_13')\n",
      "(23, 'batch_normalization_7')\n",
      "(24, 'batch_normalization_10')\n",
      "(25, 'activation_7')\n",
      "(26, 'activation_10')\n",
      "(27, 'average_pooling2d_1')\n",
      "(28, 'conv2d_9')\n",
      "(29, 'conv2d_11')\n",
      "(30, 'conv2d_14')\n",
      "(31, 'conv2d_15')\n",
      "(32, 'batch_normalization_6')\n",
      "(33, 'batch_normalization_8')\n",
      "(34, 'batch_normalization_11')\n",
      "(35, 'batch_normalization_12')\n",
      "(36, 'activation_6')\n",
      "(37, 'activation_8')\n",
      "(38, 'activation_11')\n",
      "(39, 'activation_12')\n",
      "(40, 'mixed0')\n",
      "(41, 'conv2d_19')\n",
      "(42, 'batch_normalization_16')\n",
      "(43, 'activation_16')\n",
      "(44, 'conv2d_17')\n",
      "(45, 'conv2d_20')\n",
      "(46, 'batch_normalization_14')\n",
      "(47, 'batch_normalization_17')\n",
      "(48, 'activation_14')\n",
      "(49, 'activation_17')\n",
      "(50, 'average_pooling2d_2')\n",
      "(51, 'conv2d_16')\n",
      "(52, 'conv2d_18')\n",
      "(53, 'conv2d_21')\n",
      "(54, 'conv2d_22')\n",
      "(55, 'batch_normalization_13')\n",
      "(56, 'batch_normalization_15')\n",
      "(57, 'batch_normalization_18')\n",
      "(58, 'batch_normalization_19')\n",
      "(59, 'activation_13')\n",
      "(60, 'activation_15')\n",
      "(61, 'activation_18')\n",
      "(62, 'activation_19')\n",
      "(63, 'mixed1')\n",
      "(64, 'conv2d_26')\n",
      "(65, 'batch_normalization_23')\n",
      "(66, 'activation_23')\n",
      "(67, 'conv2d_24')\n",
      "(68, 'conv2d_27')\n",
      "(69, 'batch_normalization_21')\n",
      "(70, 'batch_normalization_24')\n",
      "(71, 'activation_21')\n",
      "(72, 'activation_24')\n",
      "(73, 'average_pooling2d_3')\n",
      "(74, 'conv2d_23')\n",
      "(75, 'conv2d_25')\n",
      "(76, 'conv2d_28')\n",
      "(77, 'conv2d_29')\n",
      "(78, 'batch_normalization_20')\n",
      "(79, 'batch_normalization_22')\n",
      "(80, 'batch_normalization_25')\n",
      "(81, 'batch_normalization_26')\n",
      "(82, 'activation_20')\n",
      "(83, 'activation_22')\n",
      "(84, 'activation_25')\n",
      "(85, 'activation_26')\n",
      "(86, 'mixed2')\n",
      "(87, 'conv2d_31')\n",
      "(88, 'batch_normalization_28')\n",
      "(89, 'activation_28')\n",
      "(90, 'conv2d_32')\n",
      "(91, 'batch_normalization_29')\n",
      "(92, 'activation_29')\n",
      "(93, 'conv2d_30')\n",
      "(94, 'conv2d_33')\n",
      "(95, 'batch_normalization_27')\n",
      "(96, 'batch_normalization_30')\n",
      "(97, 'activation_27')\n",
      "(98, 'activation_30')\n",
      "(99, 'max_pooling2d_6')\n",
      "(100, 'mixed3')\n",
      "(101, 'conv2d_38')\n",
      "(102, 'batch_normalization_35')\n",
      "(103, 'activation_35')\n",
      "(104, 'conv2d_39')\n",
      "(105, 'batch_normalization_36')\n",
      "(106, 'activation_36')\n",
      "(107, 'conv2d_35')\n",
      "(108, 'conv2d_40')\n",
      "(109, 'batch_normalization_32')\n",
      "(110, 'batch_normalization_37')\n",
      "(111, 'activation_32')\n",
      "(112, 'activation_37')\n",
      "(113, 'conv2d_36')\n",
      "(114, 'conv2d_41')\n",
      "(115, 'batch_normalization_33')\n",
      "(116, 'batch_normalization_38')\n",
      "(117, 'activation_33')\n",
      "(118, 'activation_38')\n",
      "(119, 'average_pooling2d_4')\n",
      "(120, 'conv2d_34')\n",
      "(121, 'conv2d_37')\n",
      "(122, 'conv2d_42')\n",
      "(123, 'conv2d_43')\n",
      "(124, 'batch_normalization_31')\n",
      "(125, 'batch_normalization_34')\n",
      "(126, 'batch_normalization_39')\n",
      "(127, 'batch_normalization_40')\n",
      "(128, 'activation_31')\n",
      "(129, 'activation_34')\n",
      "(130, 'activation_39')\n",
      "(131, 'activation_40')\n",
      "(132, 'mixed4')\n",
      "(133, 'conv2d_48')\n",
      "(134, 'batch_normalization_45')\n",
      "(135, 'activation_45')\n",
      "(136, 'conv2d_49')\n",
      "(137, 'batch_normalization_46')\n",
      "(138, 'activation_46')\n",
      "(139, 'conv2d_45')\n",
      "(140, 'conv2d_50')\n",
      "(141, 'batch_normalization_42')\n",
      "(142, 'batch_normalization_47')\n",
      "(143, 'activation_42')\n",
      "(144, 'activation_47')\n",
      "(145, 'conv2d_46')\n",
      "(146, 'conv2d_51')\n",
      "(147, 'batch_normalization_43')\n",
      "(148, 'batch_normalization_48')\n",
      "(149, 'activation_43')\n",
      "(150, 'activation_48')\n",
      "(151, 'average_pooling2d_5')\n",
      "(152, 'conv2d_44')\n",
      "(153, 'conv2d_47')\n",
      "(154, 'conv2d_52')\n",
      "(155, 'conv2d_53')\n",
      "(156, 'batch_normalization_41')\n",
      "(157, 'batch_normalization_44')\n",
      "(158, 'batch_normalization_49')\n",
      "(159, 'batch_normalization_50')\n",
      "(160, 'activation_41')\n",
      "(161, 'activation_44')\n",
      "(162, 'activation_49')\n",
      "(163, 'activation_50')\n",
      "(164, 'mixed5')\n",
      "(165, 'conv2d_58')\n",
      "(166, 'batch_normalization_55')\n",
      "(167, 'activation_55')\n",
      "(168, 'conv2d_59')\n",
      "(169, 'batch_normalization_56')\n",
      "(170, 'activation_56')\n",
      "(171, 'conv2d_55')\n",
      "(172, 'conv2d_60')\n",
      "(173, 'batch_normalization_52')\n",
      "(174, 'batch_normalization_57')\n",
      "(175, 'activation_52')\n",
      "(176, 'activation_57')\n",
      "(177, 'conv2d_56')\n",
      "(178, 'conv2d_61')\n",
      "(179, 'batch_normalization_53')\n",
      "(180, 'batch_normalization_58')\n",
      "(181, 'activation_53')\n",
      "(182, 'activation_58')\n",
      "(183, 'average_pooling2d_6')\n",
      "(184, 'conv2d_54')\n",
      "(185, 'conv2d_57')\n",
      "(186, 'conv2d_62')\n",
      "(187, 'conv2d_63')\n",
      "(188, 'batch_normalization_51')\n",
      "(189, 'batch_normalization_54')\n",
      "(190, 'batch_normalization_59')\n",
      "(191, 'batch_normalization_60')\n",
      "(192, 'activation_51')\n",
      "(193, 'activation_54')\n",
      "(194, 'activation_59')\n",
      "(195, 'activation_60')\n",
      "(196, 'mixed6')\n",
      "(197, 'conv2d_68')\n",
      "(198, 'batch_normalization_65')\n",
      "(199, 'activation_65')\n",
      "(200, 'conv2d_69')\n",
      "(201, 'batch_normalization_66')\n",
      "(202, 'activation_66')\n",
      "(203, 'conv2d_65')\n",
      "(204, 'conv2d_70')\n",
      "(205, 'batch_normalization_62')\n",
      "(206, 'batch_normalization_67')\n",
      "(207, 'activation_62')\n",
      "(208, 'activation_67')\n",
      "(209, 'conv2d_66')\n",
      "(210, 'conv2d_71')\n",
      "(211, 'batch_normalization_63')\n",
      "(212, 'batch_normalization_68')\n",
      "(213, 'activation_63')\n",
      "(214, 'activation_68')\n",
      "(215, 'average_pooling2d_7')\n",
      "(216, 'conv2d_64')\n",
      "(217, 'conv2d_67')\n",
      "(218, 'conv2d_72')\n",
      "(219, 'conv2d_73')\n",
      "(220, 'batch_normalization_61')\n",
      "(221, 'batch_normalization_64')\n",
      "(222, 'batch_normalization_69')\n",
      "(223, 'batch_normalization_70')\n",
      "(224, 'activation_61')\n",
      "(225, 'activation_64')\n",
      "(226, 'activation_69')\n",
      "(227, 'activation_70')\n",
      "(228, 'mixed7')\n",
      "(229, 'conv2d_76')\n",
      "(230, 'batch_normalization_73')\n",
      "(231, 'activation_73')\n",
      "(232, 'conv2d_77')\n",
      "(233, 'batch_normalization_74')\n",
      "(234, 'activation_74')\n",
      "(235, 'conv2d_74')\n",
      "(236, 'conv2d_78')\n",
      "(237, 'batch_normalization_71')\n",
      "(238, 'batch_normalization_75')\n",
      "(239, 'activation_71')\n",
      "(240, 'activation_75')\n",
      "(241, 'conv2d_75')\n",
      "(242, 'conv2d_79')\n",
      "(243, 'batch_normalization_72')\n",
      "(244, 'batch_normalization_76')\n",
      "(245, 'activation_72')\n",
      "(246, 'activation_76')\n",
      "(247, 'max_pooling2d_7')\n",
      "(248, 'mixed8')\n",
      "(249, 'conv2d_84')\n",
      "(250, 'batch_normalization_81')\n",
      "(251, 'activation_81')\n",
      "(252, 'conv2d_81')\n",
      "(253, 'conv2d_85')\n",
      "(254, 'batch_normalization_78')\n",
      "(255, 'batch_normalization_82')\n",
      "(256, 'activation_78')\n",
      "(257, 'activation_82')\n",
      "(258, 'conv2d_82')\n",
      "(259, 'conv2d_83')\n",
      "(260, 'conv2d_86')\n",
      "(261, 'conv2d_87')\n",
      "(262, 'average_pooling2d_8')\n",
      "(263, 'conv2d_80')\n",
      "(264, 'batch_normalization_79')\n",
      "(265, 'batch_normalization_80')\n",
      "(266, 'batch_normalization_83')\n",
      "(267, 'batch_normalization_84')\n",
      "(268, 'conv2d_88')\n",
      "(269, 'batch_normalization_77')\n",
      "(270, 'activation_79')\n",
      "(271, 'activation_80')\n",
      "(272, 'activation_83')\n",
      "(273, 'activation_84')\n",
      "(274, 'batch_normalization_85')\n",
      "(275, 'activation_77')\n",
      "(276, 'mixed9_0')\n",
      "(277, 'concatenate_1')\n",
      "(278, 'activation_85')\n",
      "(279, 'mixed9')\n",
      "(280, 'conv2d_93')\n",
      "(281, 'batch_normalization_90')\n",
      "(282, 'activation_90')\n",
      "(283, 'conv2d_90')\n",
      "(284, 'conv2d_94')\n",
      "(285, 'batch_normalization_87')\n",
      "(286, 'batch_normalization_91')\n",
      "(287, 'activation_87')\n",
      "(288, 'activation_91')\n",
      "(289, 'conv2d_91')\n",
      "(290, 'conv2d_92')\n",
      "(291, 'conv2d_95')\n",
      "(292, 'conv2d_96')\n",
      "(293, 'average_pooling2d_9')\n",
      "(294, 'conv2d_89')\n",
      "(295, 'batch_normalization_88')\n",
      "(296, 'batch_normalization_89')\n",
      "(297, 'batch_normalization_92')\n",
      "(298, 'batch_normalization_93')\n",
      "(299, 'conv2d_97')\n",
      "(300, 'batch_normalization_86')\n",
      "(301, 'activation_88')\n",
      "(302, 'activation_89')\n",
      "(303, 'activation_92')\n",
      "(304, 'activation_93')\n",
      "(305, 'batch_normalization_94')\n",
      "(306, 'activation_86')\n",
      "(307, 'mixed9_1')\n",
      "(308, 'concatenate_2')\n",
      "(309, 'activation_94')\n",
      "(310, 'mixed10')\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### In total we have 310 layers prebuilt, we'll freeze everything but the last 2 in order to do our finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:308]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[308:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "### Lr is the learning rate, this is set currently to be relatively low \n",
    "### however, if we wanted to learn more quickly on each update we would increase this \n",
    "### THIS IS SOMETHING THAT WE CAN TEST \n",
    "## The other thing that we can check out is momentum , momentum is how much \n",
    "### the model continues to learn in the same direction. This is another model that we could check to see how \n",
    "## important it is via cross validation potentially. \n",
    "## Explanation is here http://sebastianruder.com/optimizing-gradient-descent/index.html#momentum \n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics = [\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 2s - loss: 2.8423 - acc: 0.8235 - val_loss: 2.8310 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 1s - loss: 2.8402 - acc: 0.8235 - val_loss: 2.8352 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 1s - loss: 3.7842 - acc: 0.7647 - val_loss: 2.8341 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 1s - loss: 1.7066 - acc: 0.8941 - val_loss: 2.8265 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 2s - loss: 2.8402 - acc: 0.8235 - val_loss: 2.8192 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 2s - loss: 2.0817 - acc: 0.8706 - val_loss: 2.8195 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 2s - loss: 3.4091 - acc: 0.7882 - val_loss: 2.8223 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 2s - loss: 2.8423 - acc: 0.8235 - val_loss: 2.8199 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 2s - loss: 3.0299 - acc: 0.8118 - val_loss: 2.8168 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 1s - loss: 2.2734 - acc: 0.8588 - val_loss: 2.8195 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 1s - loss: 3.5967 - acc: 0.7765 - val_loss: 2.8158 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 1s - loss: 2.2734 - acc: 0.8588 - val_loss: 2.8166 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 1s - loss: 3.4091 - acc: 0.7882 - val_loss: 2.8110 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 1s - loss: 3.4070 - acc: 0.7882 - val_loss: 2.8079 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 1s - loss: 2.0838 - acc: 0.8706 - val_loss: 2.8023 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "history_prefit = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 1), steps_per_epoch = 5, epochs = 15,validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 2.8023016452789307)\n",
      "('Test accuracy:', 0.82352948188781738)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f85730b23d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAGJCAYAAABvvYFhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85730f5dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history_prefit.history['acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title(\"Accuracy as a function of epochs\")\n",
    "#plt.subtitle(\"Note how the number of epochs effects our prefit model LESS than our other model\")\n",
    "plt.ylim([.5,.9])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tuning Parameters in the Final Two Layers: \n",
    "Let's check out some other parameters to tune to see how they affect our neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tuning  Number of Layers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f85a6e4a910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85a6e4a510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85a6e4a8d0>,\n",
       " <keras.layers.core.Activation at 0x7f85a6e4abd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85dcddded0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85a4035a10>,\n",
       " <keras.layers.core.Activation at 0x7f85dd486f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85dd453490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85dd446ad0>,\n",
       " <keras.layers.core.Activation at 0x7f85dd418c10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f85dd3d3b90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85dd3e21d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85dd392f50>,\n",
       " <keras.layers.core.Activation at 0x7f857697a2d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857698cb90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857691b850>,\n",
       " <keras.layers.core.Activation at 0x7f85768e1950>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f857689ded0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857674d6d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857673ebd0>,\n",
       " <keras.layers.core.Activation at 0x7f8576692250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857682bed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85766cfc90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857682b550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857668df50>,\n",
       " <keras.layers.core.Activation at 0x7f8576795f50>,\n",
       " <keras.layers.core.Activation at 0x7f8576622a50>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f85765babd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857689d210>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85768016d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85765e0f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576573450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857685ae90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85767bd190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85765e03d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85765389d0>,\n",
       " <keras.layers.core.Activation at 0x7f8576885f50>,\n",
       " <keras.layers.core.Activation at 0x7f8576713290>,\n",
       " <keras.layers.core.Activation at 0x7f85765cced0>,\n",
       " <keras.layers.core.Activation at 0x7f85764e1ad0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8576505950>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857636bb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576329050>,\n",
       " <keras.layers.core.Activation at 0x7f8576295990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576486f90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85762b65d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576416110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85762aaa50>,\n",
       " <keras.layers.core.Activation at 0x7f85763d9990>,\n",
       " <keras.layers.core.Activation at 0x7f8576226550>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f85761618d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576499b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85763ab450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857623cad0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85761ce350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85764c9410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576399310>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857624e750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857618dc10>,\n",
       " <keras.layers.core.Activation at 0x7f857646ebd0>,\n",
       " <keras.layers.core.Activation at 0x7f857637fe10>,\n",
       " <keras.layers.core.Activation at 0x7f8576191850>,\n",
       " <keras.layers.core.Activation at 0x7f857613ad90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85760f3d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575f87b10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575f16790>,\n",
       " <keras.layers.core.Activation at 0x7f8575ede890>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85760c9c10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575eaa910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8576070090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575e97090>,\n",
       " <keras.layers.core.Activation at 0x7f857604f150>,\n",
       " <keras.layers.core.Activation at 0x7f8575e6ea10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8575d69f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85760dfb90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8576003610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575e29910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575dacad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85760a2650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575ff6a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575e18d90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575d7cb90>,\n",
       " <keras.layers.core.Activation at 0x7f85760c9e10>,\n",
       " <keras.layers.core.Activation at 0x7f8575f70590>,\n",
       " <keras.layers.core.Activation at 0x7f8575d95890>,\n",
       " <keras.layers.core.Activation at 0x7f8575d28550>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8575d3dc90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575ccdb50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575c5a7d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575c208d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575bf1390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575bde0d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575bbaa50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575d3d7d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575b75950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575cf9f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575b63dd0>,\n",
       " <keras.layers.core.Activation at 0x7f8575cb65d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575adf8d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f8575ab3f90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8575af6b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85758bb990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575901a90>,\n",
       " <keras.layers.core.Activation at 0x7f8575828910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857583ee90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857584d110>,\n",
       " <keras.layers.core.Activation at 0x7f85757b94d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575a15690>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85757cda50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575a87b10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857575d6d0>,\n",
       " <keras.layers.core.Activation at 0x7f8575a02610>,\n",
       " <keras.layers.core.Activation at 0x7f85757247d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575996b90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85756f1e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85759a6810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85756dc110>,\n",
       " <keras.layers.core.Activation at 0x7f857596c910>,\n",
       " <keras.layers.core.Activation at 0x7f85756b7390>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f85755f2d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575a9c710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857593a3d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575672850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575600410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575ac7bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575928110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575662cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85755c8310>,\n",
       " <keras.layers.core.Activation at 0x7f8575a6fa50>,\n",
       " <keras.layers.core.Activation at 0x7f8575894d50>,\n",
       " <keras.layers.core.Activation at 0x7f85755de7d0>,\n",
       " <keras.layers.core.Activation at 0x7f857556f490>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8575583bd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85752faf10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857534ba50>,\n",
       " <keras.layers.core.Activation at 0x7f8575310b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85752cf990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575260610>,\n",
       " <keras.layers.core.Activation at 0x7f8575223710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575497ad0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85751f2dd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85754a7750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85751df050>,\n",
       " <keras.layers.core.Activation at 0x7f857546f850>,\n",
       " <keras.layers.core.Activation at 0x7f85751b72d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857543f8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575171790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857542b090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575163c10>,\n",
       " <keras.layers.core.Activation at 0x7f85754019d0>,\n",
       " <keras.layers.core.Activation at 0x7f85750dd710>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8575086ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575511850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85753bb8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85750f4c90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575086510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575541e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85753acd50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575102910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8575046dd0>,\n",
       " <keras.layers.core.Activation at 0x7f8575503550>,\n",
       " <keras.layers.core.Activation at 0x7f8575328850>,\n",
       " <keras.layers.core.Activation at 0x7f85750c8a10>,\n",
       " <keras.layers.core.Activation at 0x7f8574feef90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8574fa7910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574d51f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574d513d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574d3ced0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574d26bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574ce0110>,\n",
       " <keras.layers.core.Activation at 0x7f8574cbc1d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574f3ce10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574c71690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574f29090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574c63b10>,\n",
       " <keras.layers.core.Activation at 0x7f8574f00310>,\n",
       " <keras.layers.core.Activation at 0x7f8574bdc610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574eba7d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574bf3b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574eaac50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574c01810>,\n",
       " <keras.layers.core.Activation at 0x7f8574e28750>,\n",
       " <keras.layers.core.Activation at 0x7f8574bc6910>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8574a9a990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574f94d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574e40cd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574b173d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574add4d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574f56810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574e4f950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574b83110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574a5b450>,\n",
       " <keras.layers.core.Activation at 0x7f8574f82fd0>,\n",
       " <keras.layers.core.Activation at 0x7f8574d93a50>,\n",
       " <keras.layers.core.Activation at 0x7f8574af0d50>,\n",
       " <keras.layers.core.Activation at 0x7f8574a84a10>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8574a29810>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85747e2990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574829a90>,\n",
       " <keras.layers.core.Activation at 0x7f85747d0910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574765e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574773110>,\n",
       " <keras.layers.core.Activation at 0x7f85746de4d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85749b9690>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85746f4a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85749abb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85747056d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574928610>,\n",
       " <keras.layers.core.Activation at 0x7f85746c97d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857493cb90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574619e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574949810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574685110>,\n",
       " <keras.layers.core.Activation at 0x7f8574910910>,\n",
       " <keras.layers.core.Activation at 0x7f85745e0390>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8574519d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8575583710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85748613d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574598850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574528410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85749ec710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85748ce110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574607cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85744ed310>,\n",
       " <keras.layers.core.Activation at 0x7f8574995950>,\n",
       " <keras.layers.core.Activation at 0x7f8574838d50>,\n",
       " <keras.layers.core.Activation at 0x7f85745837d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574499490>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85744acbd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574361890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85743ce150>,\n",
       " <keras.layers.core.Activation at 0x7f8574325990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85742e1890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85742d2d10>,\n",
       " <keras.layers.core.Activation at 0x7f85742cd810>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85744ac710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8574222ed0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857446bd10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8574273a10>,\n",
       " <keras.layers.core.Activation at 0x7f8574428510>,\n",
       " <keras.layers.core.Activation at 0x7f8574236b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857443ea90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85741f3950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857444f710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85742063d0>,\n",
       " <keras.layers.core.Activation at 0x7f8574392810>,\n",
       " <keras.layers.core.Activation at 0x7f85741c86d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f857411cd90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85741891d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573f41510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573effb10>,\n",
       " <keras.layers.core.Activation at 0x7f8573ebc350>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85740ab910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573ecff50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857409a090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573ecf410>,\n",
       " <keras.layers.core.Activation at 0x7f8574071a10>,\n",
       " <keras.layers.core.Activation at 0x7f8573e39f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857402b910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573f69f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573e25c10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573d746d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f8573cf6710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857414aa90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f857401ad90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573fab950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573de1150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573d66b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573cb7f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85740e2850>,\n",
       " <keras.layers.core.Activation at 0x7f8573f95890>,\n",
       " <keras.layers.core.Activation at 0x7f8573f2c450>,\n",
       " <keras.layers.core.Activation at 0x7f8573dbe210>,\n",
       " <keras.layers.core.Activation at 0x7f8573ce1650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573ccdf10>,\n",
       " <keras.layers.core.Activation at 0x7f8574109150>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573f419d0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573cf6bd0>,\n",
       " <keras.layers.core.Activation at 0x7f8573c73650>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573c48ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85739e8810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85739930d0>,\n",
       " <keras.layers.core.Activation at 0x7f85739ba8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573b9cc50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f857398ff90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573baa8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573951990>,\n",
       " <keras.layers.core.Activation at 0x7f8573b6d9d0>,\n",
       " <keras.layers.core.Activation at 0x7f857394f490>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573b2de90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573b05b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85738e4a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573887e50>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f857379ba10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8573c87a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573b2d350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573abd090>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85738f6690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85738740d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f85737604d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8573bdd350>,\n",
       " <keras.layers.core.Activation at 0x7f8573a97e50>,\n",
       " <keras.layers.core.Activation at 0x7f8573a18150>,\n",
       " <keras.layers.core.Activation at 0x7f85738b9790>,\n",
       " <keras.layers.core.Activation at 0x7f857384f350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f85737ca410>,\n",
       " <keras.layers.core.Activation at 0x7f8573c056d0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573a4f610>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573807810>,\n",
       " <keras.layers.core.Activation at 0x7f85737199d0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8573719350>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f8573596550>,\n",
       " <keras.layers.core.Dense at 0x7f857369b6d0>,\n",
       " <keras.layers.core.Dense at 0x7f857369b750>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 264 samples, validate on 114 samples\n",
      "Epoch 1/30\n",
      "264/264 [==============================] - 6s - loss: 0.3738 - acc: 0.8311 - val_loss: 0.5991 - val_acc: 0.8302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/30\n",
      "264/264 [==============================] - 6s - loss: 0.3565 - acc: 0.8313 - val_loss: 0.4860 - val_acc: 0.8359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/30\n",
      "264/264 [==============================] - 6s - loss: 0.3514 - acc: 0.8320 - val_loss: 0.4977 - val_acc: 0.8344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/30\n",
      "264/264 [==============================] - 6s - loss: 0.3417 - acc: 0.8344 - val_loss: 0.4877 - val_acc: 0.8416\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/30\n",
      "264/264 [==============================] - 6s - loss: 0.3325 - acc: 0.8351 - val_loss: 0.4768 - val_acc: 0.8390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/30\n",
      "264/264 [==============================] - 6s - loss: 0.3258 - acc: 0.8367 - val_loss: 0.7743 - val_acc: 0.8354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/30\n",
      "264/264 [==============================] - 6s - loss: 0.3519 - acc: 0.8347 - val_loss: 0.5341 - val_acc: 0.8308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/30\n",
      "264/264 [==============================] - 6s - loss: 0.3419 - acc: 0.8349 - val_loss: 0.4810 - val_acc: 0.8369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/30\n",
      "264/264 [==============================] - 6s - loss: 0.3075 - acc: 0.8378 - val_loss: 0.5217 - val_acc: 0.8354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/30\n",
      "264/264 [==============================] - 6s - loss: 0.3372 - acc: 0.8365 - val_loss: 0.4979 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/30\n",
      "264/264 [==============================] - 6s - loss: 0.3184 - acc: 0.8353 - val_loss: 0.5722 - val_acc: 0.8313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/30\n",
      "264/264 [==============================] - 6s - loss: 0.3354 - acc: 0.8353 - val_loss: 0.5713 - val_acc: 0.8246\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/30\n",
      "264/264 [==============================] - 6s - loss: 0.3397 - acc: 0.8362 - val_loss: 0.5274 - val_acc: 0.8349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/30\n",
      "264/264 [==============================] - 6s - loss: 0.3277 - acc: 0.8387 - val_loss: 0.6271 - val_acc: 0.8308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/30\n",
      "264/264 [==============================] - 6s - loss: 0.3215 - acc: 0.8376 - val_loss: 0.5731 - val_acc: 0.8364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/30\n",
      "264/264 [==============================] - 6s - loss: 0.3047 - acc: 0.8385 - val_loss: 0.4995 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/30\n",
      "264/264 [==============================] - 6s - loss: 0.3049 - acc: 0.8360 - val_loss: 0.5303 - val_acc: 0.8344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/30\n",
      "264/264 [==============================] - 6s - loss: 0.3153 - acc: 0.8367 - val_loss: 0.5352 - val_acc: 0.8338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/30\n",
      "264/264 [==============================] - 6s - loss: 0.2969 - acc: 0.8382 - val_loss: 0.7351 - val_acc: 0.8328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/30\n",
      "264/264 [==============================] - 6s - loss: 0.3270 - acc: 0.8420 - val_loss: 0.6263 - val_acc: 0.8251\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/30\n",
      "264/264 [==============================] - 6s - loss: 0.3108 - acc: 0.8373 - val_loss: 0.4859 - val_acc: 0.8359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/30\n",
      "264/264 [==============================] - 6s - loss: 0.2931 - acc: 0.8416 - val_loss: 0.5368 - val_acc: 0.8328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/30\n",
      "264/264 [==============================] - 6s - loss: 0.3026 - acc: 0.8402 - val_loss: 0.9436 - val_acc: 0.8050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/30\n",
      "264/264 [==============================] - 6s - loss: 0.3437 - acc: 0.8340 - val_loss: 0.6120 - val_acc: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/30\n",
      "264/264 [==============================] - 6s - loss: 0.2964 - acc: 0.8387 - val_loss: 0.5270 - val_acc: 0.8369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/30\n",
      "264/264 [==============================] - 6s - loss: 0.2811 - acc: 0.8400 - val_loss: 0.5488 - val_acc: 0.8349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/30\n",
      "264/264 [==============================] - 6s - loss: 0.2865 - acc: 0.8431 - val_loss: 0.6062 - val_acc: 0.8308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/30\n",
      "264/264 [==============================] - 6s - loss: 0.3004 - acc: 0.8487 - val_loss: 0.5728 - val_acc: 0.8333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/30\n",
      "264/264 [==============================] - 7s - loss: 0.3019 - acc: 0.8393 - val_loss: 0.5559 - val_acc: 0.8308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/30\n",
      "264/264 [==============================] - 6s - loss: 0.2915 - acc: 0.8438 - val_loss: 0.5471 - val_acc: 0.8344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "history_pretrained = model.fit(x_train, y_train, epochs = 30, validation_split = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.59227250571604129, 0.82861297881161722]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f85716b05d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAGJCAYAAABvvYFhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VeW99vHvL2GeZ2QKICBgQQERJ9AgVqm2UrFW0Nah\n2lGrtbWvPXpOhQ566jmnR9+31WprlYqC1lmcUCRVUWRWkCFhDmMgQEIIkOn3/rFWYCckZCewScK6\nP9e1rr32Gp+9srPv9Tzr2WubuyMiIiInt6TaLoCIiIgkngJfREQkAhT4IiIiEaDAFxERiQAFvoiI\nSAQo8EVERCJAgS8iZZjZaWa22MxyzOz2E7jfHmaWa2Z2ovYZ7reTmX0Yvt7/OpH7royZrTOzi2u7\nHHJyaVDbBRCpKTNLA84AOrt7YS0X52Tyf4AP3H1oIndiZuuAW9z9AwB3zwRaJXKflfgBkOXurWth\n3yInjGr4Ui+ZWU9gJFACXHmC9518IvdXC3oCX9Z2IU6gnsDy2i6ESKIp8KW+ugH4FHgauCl2hpk1\nMbP/MbP1ZrY7bK5tHM4baWZzwukbzOyGcPpsM/tezDZuNLOPYp6XmNlPzCwdSA+nPWxmG8Om4Plm\nNjJm+SQzu9fMVofN1PPNrJuZ/cnM/rtceV8zszsrepFV7OPscFqOmW0tv92Y5dqY2RtmlmVm2eF4\n10qWnQWMBv4clrtvnMfmh2aWbma7zOxP5bb5fTNbHm5vmZkNMbN/ACnAG+H0u82sZ7itpHC9LuGx\nyQ63fWvMNu83s+fNbEq4/lIzG1bRawqXP9/M5oV/98/M7Lxw+lPAjcA94XaOaEY3s0Zm9t/h+2Wr\nmT0a8366yMwyzezfzGyHma01s+ti1m1lZv8Ij/06M7uvqmMTM3uomX0elnmamTUK12kf/g13h8fm\nX5W9bpEy3F2Dhno3ABnAD4FhQAHQMWben4EPgFMAA84FGhIETC7wbSAZaAucEa4zG/hezDZuBD6M\neV4CvAu0BhqH064D2hCcON8FbAUahfN+CXwO9A2fDw73dzawKWa77YE8oEMlr/No+/gEuD4cbwaM\nqGQb7YCrgMZAc+B54OWjHNvyxyKeY/M60BLoAWQBl4bzrgEygWHh81OBHuH4OmB0zHZ6AsVAUvj8\nQ+D/hX+7M8Ptpobz7gfygcvCv/EDwKeVvJ62wK7wWCYBE8LnbcP5TwG/Ocrx+F/g1fBv3xx4Dfh9\nOO8ioBD4r7CcF4Z/z37h/H8Ar4R/n57AKuDmOI/NXKBz+PdfDvwgnPcA8Gj4WpKBC2r7/1FD/Rhq\nvQAaNFR3IGjKPxjzgb0cuDMctzAIBlWw3q+AlyrZZjyhdlEV5doFDA7HVwJfr2S5L4Ex4fhtwIxq\nvPbYfaSFwde+msdvCJB9lPk1CfzzYp4/D/yfcPwd4KeV7GcdcHHM80OBT3DiUAg0i5n/APD3cPx+\nYGbMvIHAvkr28x1gbrlpnwA3hONVBX4e0Dvm+XnA2nD8IoITziblXv994es4CPSPmfcDgv4R8Ryb\niTHP/wA8Go5PJjiJ6HO8/qc0RGNQk77URzcQfNjvDp9PIwghgA4ENdm1FazXA1hzDPvdFPskbIZe\nHjat7ibocNYhZl8VlQGCWt93wvHvAM9UtsMq9nEL0B9YGTZTX1HJNpqa2eMWXOLYA/wLaGN2XHvD\nb48ZzwdahOM1PeZdgF3unh8zbQPQLeb5tnL7bFJ6OaCcruG6scpvq0Jm1pGgdr4wvFyxC3iboGWm\n1G53P1Bu210J/k4NgY2V7LeqY1PZMf2vcL2Z4SWje6p6HSKga/hSz5hZE4Im+YvC66lbgZ8BZ5rZ\nYGAncADoU8HqmUDfSja9j+CDvdQpFSxz6Kclw2vpvwS+5e5t3b0tweWC0hDNrKQMAFOBcWZ2BjCA\noLn4CFXtw93XuPt17t4ReAh40cyaVrCpXwD9gLPdvQ1BszMxZa1KPMemMkc7Dkf7qc4tQDszax4z\nLQXYXI19x26rV7lp8W5rJ0HYfsXd24VDGy/bo79tueOeEu5zJ0ErRc+YeT1j9nu0Y1Mpd89z97vd\nvQ9Bh9Wfm9no6m5HokeBL/XNVUARQRPumeEwEPiYoInWCZpo/xh2+koys3PNrCHwLDDGzL5lZslm\n1s7Mzgy3uwQYH9aG+xLUno+mJcGHeXbYqevX4bRSfwN+G24LMxtsZm0B3H0zsICgZv+Sux+syT7M\n7HozK63t5xAEaEkl29kP5JpZO2BSFa+tvOoem1h/A+4u7VBnZn3MrEc4bzvBdetYpSczmwia3R80\ns8bhydEtHKU1hMpPYN4C+pnZhPDvfi3Be2ZGVYUP309/BR4Oa/tY0Pny0nL7nWxmDc1sFHAF8IK7\nlxA07//ezFpY8M2Su2Jew9GOTeUv0uwKMys9UdhL8P9Q0d9dpAwFvtQ3NxBcx93s7lmlA/An4Pqw\nSfduYCkwH8gG/pOgI1gmcHk4fxewmOB7/BB0zCokaCZ+iqAWHqt8bfTdcEgnuN6aT1BjK/VH4AWC\nZtccgg/32FrgFGAQQfN+Zarax1jgSzPLDct/bSUnDw8T1NB3EoToW0fZJxz5Wqt7bA49d/cXgd8D\nz4XlfIWgEyHAg8B/hE3lP69gWxOB3gS15ZeA/3D32dUod2kZdgFfJ/i77wwfrwinV7pejHuA1cDc\n8JLITOC0mPlbgd1hOZ8BfujuGeG8Owj+bmsJOiFOdfenwnId7dgcrUz9gPfNbC8wB/izu6unvlTJ\nghPYBO7AbCzBB04S8KS7/6Hc/BTg70BHgg/n77j7lnDejQSdX5ygV+zRPhxF6o2wJviMu/eq7bJI\nzZnZRQR/x5TaLotIVRJaww9rW38i+OrMV4CJZjag3GL/DTzt7mcCvyGojRE2f/6a4GtM5wD3m5nu\nhCX1Xnh54U6CpmIRkRMi0U36I4AMd9/gwa1PpwPjyi1zOsHXfnD3tJj5lxH0xM5x99JmtLEJLq9I\nQoUnvLsJvl/9SC0XR0QiJNGB342y1xw3ceRXYZYA4wHMbDzQIqzdl193cwXritQr7r7S3Vu4+yh3\nz6vt8sixcfd/qTlf6ou60Gnvl0CqmS0ERhEEe3HtFklEROTkkuhfy9tM8J3UUt0p991Xd98KXA0Q\nfuf2anfPNbPNQGq5dY/ooWtmie11KCIiUge5e7VunpXoGv58oK8FP4rRiOAe1q/HLhD+EERpof+N\noMc+BF9H+qqZtQ6b+L8aTjtCbd+usL4M999/f62XoT4MOk46VjpOOk51faiJhAa+uxcDtxN0uPsS\nmO7uK8xsspl9PVwsFVhlZiuBTgTfS8WD26b+luAGJZ8Bkz3ovCciIiLVlOgmfdz9HYL7fcdOuz9m\n/CWCm2pUtO7TBD9/KiIiIsegLnTakxMkNTW1totQL+g4xU/HKj46TvHRcUqshN9pL9HMzOv7axAR\nEakOM8PrWKc9ERERqQMU+CIiIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iI\nRIACX0REJAIU+CIiIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iIRIACX0RE\nJAIU+CIiIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iIRIACX0REJAIU+CIi\nIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCEh44JvZWDNbaWbpZnZPBfN7mNkHZrbI\nzJaY2dfC6T3NLD+cvsjMHk10WUVERE5W5u6J27hZEpAOjAG2APOBCe6+MmaZx4FF7v64mQ0E3nL3\n3mbWE3jD3c+oYh+eyNcgIiJS15gZ7m7VWSfRNfwRQIa7b3D3QmA6MK7cMiVAq3C8DbA5Zl61XoyI\niIhULNGB3w3IjHm+KZwWazLwXTPLBGYAP42Z18vMFprZbDMbmdiiioiInLzqQqe9icBT7t4DuAKY\nGk7fCqS4+1nAL4DnzKxFLZVRRESkXmuQ4O1vBlJinnenbJM9wC3AZQDuPtfMmphZB3ffCRSE0xeZ\n2RrgNGBR+Z1MmjTp0HhqaiqpqanH8SWIiMjJaOdOmDEDdu+G738fWtThKmVaWhppaWnHtI1Ed9pL\nBlYRdNrbCswDJrr7iphl3gRecPcpYae999y9u5l1AHa5e4mZnQr8Cxjs7nvK7UOd9kREJC7r18Nr\nr8Grr8KiRXDJJZCcDB99BP/2b/DDH0LjxrVdyqrVuU577l4M3A7MBL4Eprv7CjObbGZfDxe7G/i+\nmS0BngVuDKdfCHxhZouAF4Aflg97ERGRo3GHL76AyZNh6FA4+2z4/HO46y7Ytg1eegleeAHefhve\nfRf694enn4aiotou+fGX0Br+iaAavoiIxCouhjlzglr8q68GoX/VVfDNb8L550ODo1zM/vhjuPde\n2LEDfvc7GD8erA5+X6wmNXwFvoiI1Hv798P77wcB/8Yb0K1bEPDf/CaccUb1Qtsd3nknCP4GDeCB\nB4Km/+MV/JmZkJYG/frBuefWbBsKfBEROent2gVLl5Ydli2DYcOCmvy4cdCr17Hvp6QEXnwR/uM/\noGtXePDBmgV0acCXDrm5kJoKP/kJjB5ds7Ip8Ou43IO5TP1iKqt3raZvu770a9ePfu370aNVD5KT\nkmu7eCISKigIrvt+9hnMmxc87t0bfEhfcgmMGQMpKVVupsZyc+HTT4Pm5b17oUMHaN++7FA6rWnT\nxJWjth04AMuXlw31pUuDYzJoEAwefHg44wxo2zYx5SgqgilTDvcD+P3vg/1XZtOmsgGfkxO8d0qH\n008/9tYCBX4dtWjrIv6y4C/8c/k/+eqpX2V41+Gs2bWGjF0ZpGenk70/m95tenNa+9MOnQSUPnZt\n2ZUkqwu3SxA5ObnDmjWHg33evCDs+/aFESPgnHOCx+bNYfbsoNn4gw+gdevD4T96dBC+NbV9e9BL\n/OOPg8dVq2D4cBg5MthudnbwFbLs7MND6fOkpLInALEnBKNGBWU72jXr2lRcHHwlrvS1bNsGX355\nOOA3bIA+fcoG++DB0LNn7VxXP3AAHnsM/vM/4dJLgxOAU0+FzZuDYJ89+3DAX3RR2YBPOs4f4wr8\nOmRfwT6e//J5/rLgL2Tty+IHZ/2A7w39Hqe0OOWIZfML81m9azUZ2RmHTgIydmWQkZ3B3oK99Gnb\n59BJwOBOgxnedTj92vfTiYBQVBQ0FxYXQ5s2QQg1bFjbparbdu6E+fODcC8N+ObNy4b7WWcd/TvZ\nJSVBIM2aFQwffRRcjx0zJhhGjYJmzSpe1x3Wrg3WKR127IALLgjWGzUq2H88Xw1zh/z8ik8GsrKC\n69AbN8K3vw3XXRe8vkQGZUkJZGTAli0Vn5yUf56bG7xnS09SOnWCgQMPB/uAAdCoUeLKW1O5ufDw\nw/B//29Q/tKAHz06cQFfngK/Dvgy60seX/g4zy59lgt6XMCPhv+Iy/pcVuMm+9yDuYdOBtKz0/ki\n6wsWbFnArv27GNZlGMO7DGd412A4te2pWF3sTloN7kFz2PLlsG5d8KFbvvbSqtXRP7RyDuSQX5hP\nl5ZdTlzBE2j//uBYrF4d1ETXrDk8vnFj8CHZqBHs2RN88DRpEoR/PEPr1sFJw969h4e8vLLPY6fl\n7nX25h8ktyCH/UV5dGnRjb69mtCnT1Aj7tPn8NCqVdWv7Xgfp+3bg6DLyjo8Hvu4fn0QNsOHHw73\nc86BLsf4VikoCE4c3n8/OAFYvDjYx5gxQStAs2ZlA97scLiPGhU0DycqIDIyYNo0eO45KCyEiROD\n8D/99OOz/fXrD7/uDz4IXmuPHmX/ZytqfWjfPmiCT67HVzOzs2Hr1hMT8OUp8GvJwaKDvLTiJf6y\n4C+s3rWaW4fdyq3DbiWldeIu8u3M38nCLQtZsGUBC7YuYOGWheQV5HFW17MY0nE4fZoOpwvDScpN\nYccOIysruNbXo8fhoVOnxL1Jcw/m8sqKV3gj/Q0aJjekc/POdGreiU7NO9G5eWfaN+1Ewe5O7FjX\niXXpzVm+PAj5lSuDkB84MGgq27evbK1g5+4CDjTaRKvumTTtspGGHTZibTZS1CyTA403sjdpI5jT\nMKkh3Zqdytd7Xse3T7+WAd260aLFif+nrEpJSfAa9+4NPjjKB/rq1cHr7tnzcJDGBmvv3kHAl3IP\nwnnPnqqH3XuK2Vg8n8JmG2nQPIekZjlYkxy8cQ4lDXMpSs6hMDmHg+RwgBzyi3PIK8ohOSmJlo1a\n0bxRc7blbaNjo550KhlM49xBFG8ZzJ70QWR+0YcWzZKPKG/peMeOQegVFQVBnZ9/+LGq8by8ikO9\nsBA6dw7e16WPseOdO0P37nDaaYl/H+TlwYcfHm4B2L+/bMD37n3im6TdYcmSIPinTQtCd+JEmDAh\neH/Fa+fOINhnzQqCPi/vcMvGgHM28lj6vTRMbkhKqxRSWqfQo3WP4LFVD5o3ap64FxgxCvw47C/c\nz3tr3+OVla/w2abPaNe0HZ1bdKZTszCMWpQNpk7NO9GmSZsKa86rd63miYVP8PSSpxlyyhB+NPxH\nfOO0b9Aw+djbVN2DWkPsB97+/cH1ropqLllZsDlnO1nJCynosICGPRdQ1Hk+SclFdCwcTkrD4XTY\nN5Li9SPZuqE5mZlBs1S3bkH4d+9e9mSgdGjfPv4Ppv2F+3kr4y2mLZvGe2vfI7VXKuNOu5qdWcms\n2JjFmm3b2bQni+z9WewtySKp1Xa82XaSrQGtG3SiU4tO9GzXmW5tOh067tvytrExdyOZOZlszNnI\nzvydnNKiC12apdChYQptSKFZUQ8aH0ghaW8KxbtSyMtuzc7sYjYmz2Zz22nkdHkVyzqDki8m0mrT\nt2jXpP1Ra70tWtT8w7igoOpacuyQnx/UiFq2DAKpolDv0eP41YIKiguYvW42L694mddWvUbH5h0Z\n2GEgrRq3onXj1rRu0rrMY6vGrY6Y1rhB4zLbW7VzFcuylrE0a+mhx6x9WfRpPYBuDQfT+sBgknYO\nIn/dYDav6sLaNUZ+fnAZorg4eP3NmgUnpPGMN29ecZi3bFn3vi+9M38n9866lyXbljCo0yAGdxoc\nPHYeTOfmnWutRa6kJGhpeO654MYzAwcGtf5rrglOBGLt2xcsW1qLX7sWLrzwcMgPGhQc9xnpM7jl\n9Vu47ezb6NayGxtzNpKZG/zflo43b9j80AlASqvDJwOlQ5cWXdSBOU4K/ErkHszlrYy3eHnFy7y7\n5l2GnjKU8QPHc2HPC8k9mMv2vO1k7cs6NGzft73M+P7C/XRs3rFMLXVr3lY+3/Y5Nw25iR+c9QP6\ntutb4b4LCoKOJ7HNsdu2VV2b2b8/+JCP/cBr2jQIpM6dj6zJxD7GNnlv2buFBVsWMH/zfP614V8s\n2rqIs7qexZjeYxjZdQynlIxg2+aGbNoUXAsuPxw8GJwUNGoUfDgXFR3+oC4uhqKSIg50fZ/9fadR\neOrrJG0fRtKXE/HlV1Oc15akpKCmfvrpwYfK6acHw4ABQbC6O3kFeWWOeda+LLbnbWfPgT2c0uKU\nMh8KNflAOFB0gHdWv8OzXzzHu2veZXjHUVzccSJDmo7j4N4WR9R88/KqtfkyGjYMgqdFi+Axdqho\nWvPmsGDrPO569y7W71nP+T3OZ2SPkVyQcgFDThlCg6Rj7221r2Af7655l1dWvsKb6W/Sv0N/xg8Y\nz1UDr6r0fXuscg/msnzHcpZuP3wSsDRrKSVewqBOg+jX5nRaN2lJ00aNadqgCY0bNKZJgyY0Tm5c\nZrxJOC92vGmDpodORI7H8UmEEi/h74v/zn0f3Md1g67j6tOvPnw8dixj6falAAzuPJhBHYMTgEGd\nBjGo0yBaNT6x10IKCmDmzCD833or6Etw9dXBpbVZs2DhwqBPQWkHxbPPLttPpLC4kPs+uI/py6Yz\n7eppXJByQYX7cXd25u8scwJQfnz3/t0M7TKUC3pcwMiUkZzf43w6NOtQ4fbqq9jW2XO6n8Mlp15S\no+0o8GPs2LeD11e9zssrX+ajDR8xqucoxg8Yz5X9r6Rj847V2seBogPs2LejzMlAs4bNuLL/lTRp\n0IR9+45sii0d37IlCMzYWluXLodrLJXVZpo2TUzP2n0F+/ho40fMWjuLWetmsXrXakamjGRM7zGM\nOXUMZ3Q+o0xnwLy84B+/qCgoT3IyWFIJS7I/4Y3103hr/Yv0bNWbq0+byPgB36Zbqy4kJwfLNWhQ\n95rQ9x7cy2urXmPasml8vPFjxvYdy8RBE/la36+VqbmeCFv3buXeD+7l3dXv8sCYBxiVMopPMj9h\nTuYcPt74MRtyNjCi24hDJwDndj837jDYc2APM9Jn8PKKl3l/7fuM6DaC8QPHM67/OLq1Kv8L1SeG\nu5O1L4ulWUtZuXMl+wr2cbD4IAeKDnCwKHwsPljxtJjx/MJ8cg/mknswlyYNmlTeIlFBi0WvNr0Y\ncsqQhNasl2xbwo/f/DGG8dgVj3HmKWdWeCy25W07omVk+Y7ldGzWsUxrwDf6f+OEnQTk5cHrrwc3\nr+nZMwj5kSODE9OKbMrdxIQXJ9CycUueueqZYw7nvII85m2ex8cbP2ZO5hzmbppL15ZdD50AXNDj\nAvq263tMf7/9hftZs3vNoU7SGdkZ5Bbk0qdtnzLflOrYrOMxv0/2HNhT5tJr+f5X3/7Ktzm729k1\n2nbkAz8zJ5NXVr7CKytfYfHWxVza51LGDxzP5f0uL/MP4x40aRUWHv364dFq4dnZh4M9Jye4JldR\nx6WePetmL9NS2fnZpK1PY9a64ARg1/5djO41mot7X8yY3mMO/XO5O0u2LWHasmlMXzad1k1aM3HQ\nRCYMmsCpbU+t7ZdRIzvzd/LS8peYtmwaS7OW8s3+32Ti4ImM7jU6oc2KB4sO8shnj/DQnIe4Zegt\n3HfhfRV+oO/av4tPMz9lTuYc5mTOYeGWhfRr3+/QCcDIlJF0b9X90PLb8rbx2srXeHnly3ya+Smj\ne49m/IDxfP20r9O+2TF8Z6yOcnf2Fe4j50AOOQdzjnjMPZh7eFo4/YvtX9ChWQd+du7P+Nbp36JR\n8vH758w9mMuvZ/+aacum8cDFD3Dz0Jur/U2a4pJi1u1Zd6hlJG1DGs0bNue1Ca/VuQ6576x+h5te\nvYk7z7mTe0bek5BvDRWXFLM0a+mhE4CPN35MQXEBF/S44NBJwNAuQ4/4OxYUF7B299oyoZ6+K52M\n7Ayy9mXRq00v+rXvx2ntTqNf+360bNQyOAkIl83YlUFRSRH92vWr8OvS7Zq2O6Ksew/uZdHWRWXC\nfVveNoaeMvRQx+rhXYfTt13f43KsIhv47cc9SF6PlylssZYmG79B47XjSV5/CSUFTcs2P4fN0SUl\nQc2zYcPKa9dVTWvT5nDAd+lS92qyNbUpdxOz1s7ig/UfMGvtLJIsiVE9R7Fo6yIOFh1kwqAJTBw0\nkcGdB9d2UY+rTbmbeOHLF5i2bBqbczfznTO+w81DbmZgx4HHbR/uzoz0Gfx85s8Z0GEAf7z0j/Rr\n3y/u9QuKC1i0ddGhD785G+fQtGFTzu9xPptyN7F0+1Iu73c5Vw24iq/1+xotGtXh3/qsJcUlxbyZ\n8SYPz32YVdmr+PHwH/PDs35Y7Va/WO7O818+zy9m/oLL+17Og5c8eNyaoQuKCxj6+FAmXTSJa75y\nzXHZ5rEqKini/tn3M+XzKTx39XNc2PPCE7r/jTkbmbNxzqH/g9W7VjO863D6t+/P+pz1ZGRnsHnv\nZnq06lEm1EvDOqV1SlyXgrLzs8ucAMSON0hqcOhEwHEWbFnAxpyNnNn5zDLh3r99/4RVHiIb+Nc9\nextjU8ZzXtcLadywQZkm5dLx2OdJSXWvc09d5O6kZ6fz0caPGNRpEOd0O6fO1TISYcWOFUz5fAr/\n+PwfpLRO4aYhNzFh0ATaNGlzTNu869272JCzgf+97H8Z23fsMZfT3cnYlcEnmZ/QsVlHLjn1khN+\nWaI++2L7Fzwy9xFeXvky4weM585z7+SMzmdUaxurdq7itrduY2f+Th674jHO63HecS/nJ5mf8K0X\nvsWXP/mStk0TdCu5OG3Zu4XrXrqORsmNmDp+Kp2ad6rV8kDwNdy5m+ayetfqQzX33m16H5fO0xVx\nd3bk7wjul5KdgeMM7zqcgR0GJmyfFYls4Nf31yB1U1FJEe+teY+nljzFzDUz+Vq/r3HzkJsZ03tM\n3Gftew7sYXLaZKYuncp9o+7jtrNvO6EfClK1Hft28MTCJ3h0waP0b9+fn537M67od8VR/8b5hfk8\n8NEDPL7wcf591L9z24jbEtqB8LY3b6OguIC/XvnXhO2jKrPWzuK7r3yXHw//MfeOule96WuZAl8k\nQbLzs5m+bDpPLXmK7fu2c8MZN3DTkJsqbZIvLinmycVP8uvZv+bK/lfyu4t/VydqQ1K5guICXlz+\nIg/PfZjs/dncMeIObh568xH9K2akz+Cnb/+Uc7ufy/9c+j90bdk14WXLPZjLVx79Cs9c9QypvVIT\nvr9YxSXF/PbD3/LEwieYOn4qF/e++ITuXyqmwBc5AZZuX8rTS55m6tKp9GvXj5uH3Mw1X7nmUDB8\ntOEj7nznTpo3as4jYx9hWJdhtVxiqQ53Z+6muTzy2SPMXDOTG868gZ+O+CkNkhpw5zt3smLnCv58\n+Z9r/HWqmnp91evcPfNuPv/R5zRteGJ+MWd73nauf/l6ir2YaVdPq/DW4FI7FPgiJ1BhcSFvr36b\np5Y8xex1s7my/5UUFBfwSeYnPPTVh7j2K9dGos/DySwzJ5NH5z/K3xb/jeKSYn5x3i+4+/y7a62v\nxDX/vIbT2p3G78f8PuH7SlufxvUvX88tQ2/h/ovuVxN+HaPAF6klWfuyePaLZzlQdIA7zrlDtxA9\nyeQX5rOvYN8x9eY/HrblbeOMx87g/Rver3YHw+p4aM5D/O/c/2XKN6dwaZ9LE7YfqTkFvojISe5v\ni/7GEwuf4NNbPk1Irfv3H/6e55Y9x8zvzKy1mzRJ1WoS+CfJt8dFRKLhlqG30KxhM/4070/HfdsP\nz32YKZ+rLNxwAAAZI0lEQVRP4f3vvq+wPwmphi8iUs+kZ6dz/pPns/AHC+nZpho/dXcUTyx8ggc+\neoAPb/4wob/0KceHavgiIhFwWvvT+Pl5P+fHb/6Y41HhmfrFVH7zr98w64ZZCvuTmAJfRKQe+uX5\nv2RT7iamL5t+TNt5ecXL/PK9XzLzuzPp067PcSqd1EUKfBGReqhhckP++o2/cte7d5Gdn12jbbyV\n8RY/fvPHvH3925ze8fTjXEKpa3QNX0SkHvvZOz9jz4E9PP3Np6u13ux1s7n2xWt5Y+IbnNP9nMQU\nThJG1/BFRCLmdxf/jtnrZ/PemvfiXueTzE+49sVr+ec1/1TYR4gCX0SkHmvRqAWPXfEYP3rzR+QX\n5le5/KKti7jq+at45qpnuKjXRSeghFJXKPBFROq5y/tdzohuI5iUNumoyy3LWsblz17O419/nMv6\nXnZiCid1hq7hi4icBLL2ZTH4scG8ff3bFf5gU0Z2BqlTUvnvr/43EwdPrIUSyvGka/giIhHVqXkn\n/nDJH7j19VspKikqM2/Dng1c8swl/Cb1Nwr7CFPgi4icJG4880baNW3Hw3MfPjRty94tjPnHGO4+\n725uGXZLLZZOapua9EVETiJrdq3hnL+dw7zvz6Nlo5Zc9PRF3HDmDfxq5K9qu2hyHOnX8kREhIfm\nPMTbq99mz4E9fL3f1/ntxb+t7SLJcVYnr+Gb2VgzW2lm6WZ2TwXze5jZB2a2yMyWmNnXYub9m5ll\nmNkKM9OPMouIxOHn5/2cfQX7GNN7DL8Z/ZvaLo7UEQmt4ZtZEpAOjAG2APOBCe6+MmaZx4FF7v64\nmQ0E3nL33mZ2OvAscDbQHXgf6Fe+Oq8avojIkUq8hCRTN62TVV2s4Y8AMtx9g7sXAtOBceWWKQFa\nheNtgM3h+JXAdHcvcvf1QEa4PRERqYLCXspL9DuiG5AZ83xTOC3WZOC7ZpYJzAB+Wsm6mytYV0RE\nROJQF04BJwJPuXsP4Apgai2XR0RE5KTTIMHb3wykxDzvzuEm+1K3AJcBuPtcM2tiZh3iXBeASZMm\nHRpPTU0lNTX1WMstIiJSZ6SlpZGWlnZM20h0p71kYBVBp72twDxgoruviFnmTeAFd58Sdtp7z927\nx3TaO4egKf891GlPRESkRp32ElrDd/diM7sdmElw+eBJd19hZpOB+e4+A7gb+KuZ3UXQge/GcN3l\nZvYCsBwoBH6iZBcREakZ3XhHRESknqmLX8sTERGROkCBLyIiEgEKfBERkQhQ4IuIiESAAl9ERCQC\nFPgiIiIRoMAXERGJAAW+iIhIBCjwRUREIkCBLyIiEgEKfBERkQhQ4IuIiESAAl9ERCQCFPgiIiIR\noMAXERGJAAW+iIhIBCjwRUREIkCBLyIiEgEKfBERkQhQ4IuIiESAAl9ERCQCFPgiIiIRoMAXERGJ\nAAW+iIhIBCjwRUREIkCBLyIiEgEKfBERkQhQ4IuIiESAAl9ERCQCFPgiIiIRoMAXERGJAAW+iIhI\nBCjwRUREIiDhgW9mY81spZmlm9k9Fcz/o5ktNrNFZrbKzHbFzCsOpy82s1cTXVYREZGTlbl74jZu\nlgSkA2OALcB8YIK7r6xk+duBIe5+a/g8191bVbEPT+RrEBERqWvMDHe36qyT6Br+CCDD3Te4eyEw\nHRh3lOUnAtNinlfrxYiIiEjFEh343YDMmOebwmlHMLMUoBfwQczkxmY2z8w+MbOjnSiIiIjIUTSo\n7QLEmAC8WK59vqe7bzWz3sAHZvaFu6+rpfKJiIjUW4kO/M1ASszz7uG0ikwAfhI7wd23ho/rzCwN\nGAocEfiTJk06NJ6amkpqauoxFFlERKRuSUtLIy0t7Zi2kehOe8nAKoJOe1uBecBEd19RbrkBwFvu\nfmrMtDZAvrsXmFkHYA4wrnyHP3XaExGRqKlJp72E1vDdvTjseT+ToL/Ak+6+wswmA/PdfUa46LUE\nHfpiDQQeN7PicN0HK+vdLyIiIkeX0Br+iaAavoiIRE1d/FqeiIiI1AEKfBERkQhQ4IuIiESAAl9E\nRCQCFPgiIiIRoMAXERGJAAW+iIhIBCjwRUREIkCBLyIiEgEKfBERkQhQ4IuIiESAAl9ERCQCFPgi\nIiIRoMAXERGJAAW+iIhIBCjwRUREIkCBLyIiEgFxBb6ZvWxmV5iZThBERETqoXgD/FHgOiDDzP7T\nzPonsEwiIiJynJm7x7+wWWtgInAfkAn8FZjq7oWJKV5cZfLqvAYREZH6zsxwd6vOOnE30ZtZe+Am\n4FZgMfAIMAx4rzo7FBERkROvQTwLmdkrQH/gGeAb7r41nPW8mS1IVOFERETk+IirSd/MRrv77BNQ\nnmpTk76IiERNIpv0TzezNjE7amtmP6lW6URERKTWxFvDX+LuQ8pNW+zuQxNWsjiphi8iIlGTyBp+\nspkd2rCZJQONqrMjERERqT1xddoD3iHooPd4+PyH4TQRERGpB+Jt0k8iCPkx4aT3gL+5e3ECyxYX\nNemLiEjU1KRJv1o33qmLFPgiIhI1NQn8eL+H3w94EDgdaFI63d1PrVYJRUREpFbE22nvKeAxoAgY\nDfwDmJqoQomIiMjxFW/gN3X3WQSXADa4+yTgisQVS0RERI6neHvpHww77mWY2e3AZqBF4oolIiIi\nx1O8Nfw7gWbAHcBZwHeAG+NZ0czGmtlKM0s3s3sqmP9HM1tsZovMbJWZ7YqZd2O43iozuyHOsoqI\niEg5VfbSD2+y8wd3v7vaGw9aBdIJvs63BZgPTHD3lZUsfzswxN1vNbO2wAKCX+QzYCEwzN1zyq2j\nXvoiIhIpCbnTXvhd+5E1LNMIICO87l8ITAfGHWX5icC0cPwyYKa757j7HmAmMLaG5RAREYm0eK/h\nLzaz14F/AvtKJ7r7y1Ws1w3IjHm+ieAk4AhmlgL0Aj6oZN3N4TQRERGppngDvwmQDVwcM82BqgK/\nOiYAL9akfX7SpEmHxlNTU0lNTT1+pRIREallaWlppKWlHdM2EnqnPTM7F5jk7mPD578C3N3/UMGy\ni4CfuPvc8PkEINXdfxQ+/wsw292fL7eeruGLiEikJOzWumb2FEGNvgx3/14V6yUDqwg67W0F5gET\n3X1FueUGAG/F3rmvXKe9pHD8rPB6fuy6CnwREYmUhN1aF5gRM94EuIqg1/1RuXtx2PN+JkFoP+nu\nK8xsMjDf3Uu3ey1Bh77YdXeb2W8Jgt6ByeXDXkREROJToyb98Ot2H7v7+ce/SNUui2r4IiISKQn5\nWl4l+gGdariuiIiInGDx/lreXspew98GHHHXPBEREamb4gp8d2+Z6IKIiIhI4sTVpG9mV5lZ65jn\nbczsm4krloiIiBxP8X4tb4m7Dyk3bbG7D01YyeKkTnsiIhI1iey0V9Fy8X6lT0RERGpZvIG/IPwZ\n2z7h8EeCX68TERGReiDewP8pUAA8T3CDnAPAbYkqlIiIiBxfCb2X/omga/giIhI1CbuGb2bvmVmb\nmOdtzezd6hZQREREake8TfodYu9j7+670Z32RERE6o14A7/EzFJKn5hZLyr49TwRERGpm+L9at19\nwMdm9i/AgFHADxJWKhERETmu4u60Z2adCEJ+MdAUyHL3DxNYtrio056IiERNTTrtxfvjObcCdwLd\ngSXAucCnwMXVLaSIiIicePFew78TOBvY4O6jgaHAnqOvIiIiInVFvIF/wN0PAJhZY3dfCfRPXLFE\nRETkeIq3096m8Hv4rwLvmdluYEPiiiUiIiLHU7XvtGdmFwGtgXfcvSAhpapeedRpT0REIqUmnfZ0\na10REZF6JpE/jysiIiL1mAJfREQkAhT4IiIiEaDAFxERiQAFvoiISAQo8EVERCJAgS8iIhIBCnwR\nEZEIUOCLiIhEgAJfREQkAhT4IiIiEaDAFxERiYCEB76ZjTWzlWaWbmb3VLLMt83sSzNbamZTY6YX\nm9kiM1tsZq8muqwiIiInq4T+Wp6ZJQHpwBhgCzAfmODuK2OW6Qs8D4x291wz6+DuO8N5ue7eqop9\n6NfyREQkUurir+WNADLcfYO7FwLTgXHllvk+8Gd3zwUoDftQtV6MiIiIVCzRgd8NyIx5vimcFus0\noL+ZfWxmn5jZZTHzGpvZvHB6+RMFERERiVOD2i4AQRn6AhcCKcCHZjYorPH3dPetZtYb+MDMvnD3\ndbVZWBERkfoo0YG/mSDES3UPp8XaBMx19xJgvZmlA/2Ahe6+FcDd15lZGjAUOCLwJ02adGg8NTWV\n1NTU4/cKREREallaWhppaWnHtI1Ed9pLBlYRdNrbCswDJrr7iphlLgun3WRmHYCFwBDAgXx3Lwin\nzwHGxXb4C9dXpz0REYmUmnTaS2gN392Lzex2YCZBf4En3X2FmU0G5rv7DHd/18wuNbMvgSLgbnff\nbWbnAY+bWXG47oPlw15ERETik9Aa/omgGr6IiERNXfxanoiIiNQBCnwREZEIUOCLiIhEgAJfREQk\nAhT4IiIiEaDAFxERiQAFvoiISAQo8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQkAhT4IiIi\nEaDAFxERiQAFvoiISAQo8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQkAhT4IiIiEaDAFxER\niQAFvoiISAQo8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQkAhT4IiIiEaDAFxERiQAFvoiI\nSAQo8EVERCJAgS8iIhIBCQ98MxtrZivNLN3M7qlkmW+b2ZdmttTMpsZMvzFcb5WZ3ZDosoqIiJys\nzN0Tt3GzJCAdGANsAeYDE9x9ZcwyfYHngdHunmtmHdx9p5m1BRYAwwADFgLD3D2n3D48ka9BRESk\nrjEz3N2qs06ia/gjgAx33+DuhcB0YFy5Zb4P/NndcwHcfWc4/TJgprvnuPseYCYwNsHlFREROSkl\nOvC7AZkxzzeF02KdBvQ3s4/N7BMzu6ySdTdXsK6IiIjEoUFtF4CgDH2BC4EU4EMzG1S7RRIRETm5\nJDrwNxOEeKnu4bRYm4C57l4CrDezdKBfuFxquXVnV7STSZMmHRpPTU0lNTW1osVERETqpbS0NNLS\n0o5pG4nutJcMrCLotLcVmAdMdPcVMctcFk67ycw6EHTOGxLOLu20lxSOnxVez4/dhzrtiYhIpNSk\n015Ca/juXmxmtxN0uEsCnnT3FWY2GZjv7jPc/V0zu9TMvgSKgLvdfTeAmf2WIOgdmFw+7EVERCQ+\nCa3hnwiq4YuISNTUxa/liYiISB2gwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iI\nRIACX0REJAIU+CIiIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iIRIACX0RE\nJAIU+CIiIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iIRIACX0REJAIU+CIi\nIhGgwBcREYkABb6IiEgEKPBFREQiQIEvIiISAQp8ERGRCFDgi4iIRIACX0REJAIU+CIiIhGQ8MA3\ns7FmttLM0s3sngrm32hmWWa2KBy+FzOvOJy22MxeTXRZRURETlbm7onbuFkSkA6MAbYA84EJ7r4y\nZpkbgbPc/Y4K1s9191ZV7MMT+RpERETqGjPD3a066yS6hj8CyHD3De5eCEwHxlWwXGWFrtaLERER\nkYolOvC7AZkxzzeF08obb2ZLzOwFM+seM72xmc0zs0/MrKITBREREYlDXei09zrQy92HAO8DU2Lm\n9XT3EcD1wMNm1rs2CigiIlLfNUjw9jcDKTHPu4fTDnH33TFP/wY8FDNva/i4zszSgKHAuvI7mTRp\n0qHx1NRUUlNTj7ngIiIidUVaWhppaWnHtI1Ed9pLBlYRdNrbCswDJrr7iphlTnH3beH4VcAv3f18\nM2sD5Lt7gZl1AOYA42I7/IXrqNOeiIhESk067SW0hu/uxWZ2OzCT4PLBk+6+wswmA/PdfQZwh5ld\nCRQCu4CbwtUHAo+bWXG47oPlw15ERETik9Aa/omgGr6IiERNXfxanoiIiNQBCnwREZEIUOCLiIhE\ngAJfREQkAhT4IiIiEaDAFxERiQAFvoiISAQo8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQk\nAhT4IiIiEaDAFxERiQAFvoiISAQo8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQkAhT4IiIi\nEaDAFxERiQAFvoiISAQo8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQkAhT4IiIiEaDAFxER\niQAFvoiISAQo8EVERCJAgS8iIhIBCQ98MxtrZivNLN3M7qlg/o1mlmVmi8Lhe+XmpZvZKjO7IdFl\nFREROVklNPDNLAn4E3AZ8BVgopkNqGDR6e4+LBz+Hq7bFvg1cDZwDnC/mbVOZHlPdmlpabVdhHpB\nxyl+Olbx0XGKj45TYiW6hj8CyHD3De5eCEwHxlWwnFUw7TJgprvnuPseYCYwNnFFPfnpnyk+Ok7x\n07GKj45TfHScEivRgd8NyIx5vimcVt54M1tiZi+YWen88uturmRdERERqUJd6LT3OtDL3YcA7wP/\nqOXyiIiInHTM3RO3cbNzgUnuPjZ8/ivA3f0PlSyfBGS7e1szmwCkuvuPwnl/AWa7+/Pl1kncCxAR\nEamj3L2iy+GVSnTgJwOrgDHAVmAeMNHdV8Qsc4q7bwvHrwJ+6e7nh532FgDDCFoiFgBnhdfzRURE\npBoaJHLj7l5sZrcTdLhLAp509xVmNhmY7+4zgDvM7EqgENgF3BSuu9vMfksQ9A5MVtiLiIjUTEJr\n+CIiIlI31IVOezVW1U19JGBm683sczNbbGbzars8dYmZPWlm283si5hpbc1sZnjDp3d1/4dKj9P9\nZrYp5qZZkf/arJl1N7MPzOxLM1tqZneE0/WeKqeCY/XTcLreVzHMrLGZfRZ+fi81s/vD6b3MbG6Y\nf9PMrMoW+3pbww87+KUT9A/YAswHJrj7ylotWB1kZmsJ+j/sru2y1DVmNhLIA/7h7meE0/5A0Hn0\nofBEsq27/6o2y1nbKjlO9wN73f2PtVq4OsTMTgFOcfclZtYCWEhw75Gb0XuqjKMcq2vR+6oMM2vm\n7vlhv7g5wJ3Az4EX3f2fZvYYsMTdHz/adupzDT/em/pIcGOj+vy3Thh3/xgofyI0DpgSjk8BvnlC\nC1UHVXKcoOKbZkWWu29z9yXheB6wAuiO3lNHqORYld5rRe+rGO6eH442Juh758Bo4KVw+hTgqqq2\nU59DIN6b+kjw5njXzOab2fdruzD1QCd33w7BhxLQqZbLU5fdFt40629qpi7LzHoBQ4C5QGe9pyoX\nc6w+CyfpfRXDzJLMbDGwDXgPWAPscfeScJFNQNeqtlOfA1/id4G7DwcuJ/hHGlnbBapn6ud1r8R7\nFOgT3jRrG6Am2FDYRP0icGdYey3/HtJ7KlTBsdL7qhx3L3H3oQStRSOAin6Tpkr1OfA3Aykxz7uH\n06Qcd98aPu4AXiF4w0jltptZZzh0nTGrlstTJ7n7Dj/cCeivBD90FXlh56kXgWfc/bVwst5TFajo\nWOl9VTl3zwXSgPOANmFfNogz/+pz4M8H+ppZTzNrBEwguE2vxDCzZuEZNGbWHLgUWFa7papzjLLX\nDF8nvB8EcCPwWvkVIqrMcQqDq9R49L4q9Xdgubs/EjNN76mKHXGs9L4qy8w6lF7WMLOmwFeB5cBs\n4JpwsbjeU/W2lz4EX8sDHuHwTX3+s5aLVOeYWW+CWr0TdPZ4VsfpMDN7DkgF2gPbgfuBV4F/Aj2A\nDcC3o37Tp0qO02iC664lwHrgh6XXqaPKzC4APgSWEvzPOXAvwV1GX0DvqUOOcqyuQ++rQ8xsMEGn\nvKRweN7dfx9+tk8H2gKLge+EHdgr31Z9DnwRERGJT31u0hcREZE4KfBFREQiQIEvIiISAQp8ERGR\nCFDgi4iIRIACX0REJAIU+CKSMGZ2kZm9UdvlEBEFvogknm72IVIHKPBFBDO73sw+M7NFZvZY+Otc\ne83sj2a2zMzeM7P24bJDzOzT8NfMXoq57WefcLklZrYgvBMYQEsz+6eZrTCzZ2rtRYpEnAJfJOLM\nbABwLXC+uw8juKXp9UAzYJ67DyK4Ber94SpTgF+Gv2a2LGb6s8D/C6efD2wNpw8B7gBOB/qY2fmJ\nf1UiUl6D2i6AiNS6McAwYL6ZGdCE4H75JQT3fweYCrxkZq2A1u7+cTh9CvBC+ANN3dz9dQB3LwAI\nNse80l9sNLMlQC/gkxPwukQkhgJfRAyY4u73lZlo9h/llvOY5avjYMx4MfrcEakVatIXkVnAt8ys\nI4CZtTWzFCAZ+Fa4zPXAx+Hvce8Kf+kM4LvAv9w9D8g0s3HhNhqFP+UpInWEzrRFIs7dV5jZvwMz\nzSwJKABuB/YBI8Ka/naC6/wQ/Pb242GgrwVuDqd/F3jCzH4TbuMajqQe+yK1RD+PKyIVMrO97t6y\ntsshIseHmvRFpDKqDYicRFTDFxERiQDV8EVERCJAgS8iIhIBCnwREZEIUOCLiIhEgAJfREQkAhT4\nIiIiEfD/AbEAHT9AFwanAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8571663090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history_pretrained.history['acc'], label = \"trainin set\")\n",
    "plt.plot(history_pretrained.history['val_acc'], label = \"test set\")\n",
    "plt.legend\n",
    "plt.title(\"Accuracy as a function of epochs\")\n",
    "#plt.subtitle(\"Note how the number of epochs effects our prefit model LESS than our other model\")\n",
    "plt.ylim([.5,.9])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway: It  appears that epochs do not matter much for our pretrained data \n",
    "Overall, it seems that the number of epochs that we run for our pretrained data does not seem to have a significant effect on our accuracy. At  the very end we have a very slight improvement in our model, but it does not seem to be that large of a change (no where near as large as it is for our model built from scratch) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8280650686334678, 0.81989835662606325]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baserate Accuracy \n",
    "This is a benchmark accuracy that we are trying to beat. It shows that we hvave an accuracy of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293391430646333"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list = [] \n",
    "for y in y_test: \n",
    "    for x in y:\n",
    "        accuracy_list.append(x == 0)\n",
    "    \n",
    "np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Discussion of the results, how much improvement you gained with fine tuning, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Discussion of at least one additional exploratory idea you pursued \n",
    "In this section, we might want to add in other features/other ideas etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
